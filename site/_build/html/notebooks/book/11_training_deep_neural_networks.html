

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Setup &#8212; MGMT 4190/6560 Introduction to Machine Learning Applications @Rensselaer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/mystnb.js"></script>
    <script src="../../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">MGMT 4190/6560 Introduction to Machine Learning Applications @Rensselaer</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Welcome to Introduction to Machine Learning Applications
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  OVERVIEW
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/schedule.html">
   Schedule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/syllabus.html">
   Syllabus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/preparation.html">
   Before Class
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/in_class.html">
   In Class
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/assignments.html">
   Assignments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/capstone.html">
   <strong>
    The MS Business Analytics Capstone Course
   </strong>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/capstone.html#prior-examples">
   Prior Examples
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/capstone.html#faculty">
   Faculty
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  SESSIONS
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session1.html">
   1. Course Overview &amp; Introduction to the Data Science Lifecycle (08/31)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session2.html">
   2. Python Basics (09/03)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session3.html">
   3. Python Basics  (First in Person Class, Tuesday follow Monday Schedule) (09/08)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session4.html">
   4. Python conditionals, loops, functions, aggregating.  (09/10)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session5.html">
   5. Python conditionals, loops, functions, aggregating (continued)  (09/14)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session6.html">
   6. Python visualization, data manipulation , and feature creation. (09/17)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session7.html">
   7. Python visualization, data manipulation , and feature creation (continued) (09/21)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session8.html">
   8. Overview of Modeling (09/24)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session9.html">
   9. Overview of Classification (09/28)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session10.html">
   10. Overview of Classification (10/01)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session11.html">
   11. Python and Regression (10/05)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session12.html">
   12. Python and Regression (10/08)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session13.html">
   13. Unsupervised Models (10/15)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session14.html">
   14. Midterm Exam (10/19)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session15.html">
   15. Time Series Analysis  (10/22)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session16.html">
   16. Time Series Analysis (10/26)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session16.html">
   16. Time Series Analysis (10/26)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session17.html">
   17. Text and NLP (10/29)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session18.html">
   18. Text and NLP (11/02)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session19.html">
   19. Introduction to Deep Learning (11/05)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session19.html">
   19. Introduction to Deep Learning (11/05)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session20.html">
   20. Introduction to Deep Learning (11/09)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session21.html">
   21. Introduction to Deep Learning (11/12)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session22.html">
   22. Image Data and Deep Learning (11/16)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session23.html">
   23. NLP and Deep Learning (11/19)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session24.html">
   24. R and Machine Learning (11/23)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session25.html">
   25. Big Data (11/30)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session26.html">
   26. Open project questions.  (12/03)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session27.html">
   27. Final Presentations (12/07)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session28.html">
   28. Final Presentations  (12/10)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../sessions/session29.html">
   29. Final Exam (12/15)
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  NOTEBOOKS
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../01-intro-python/01-python-overview.html">
   1. Overview of Python Features
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01-intro-python/02-datastructures.html">
   2. Introduction Datastructures (Varibles, Lists, Dictionaries, and Sets)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01-intro-python/03-numpy.html">
   3. Overview of Numpy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../01-intro-python/04-pandas.html">
   4. Introduction to Pandas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02-intro-python/01-conditionals-loops.html">
   5. Conditional Statements and Loops
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02-intro-python/02-functions.html">
   6. Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02-intro-python/03-null-values.html">
   7. Null Values
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02-intro-python/04-groupby.html">
   8. Groupby and Pivot Tables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02-intro-python/04-pivottable.html">
   9. More Pivottables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02-intro-python/05-kaggle-baseline.html">
   10. Kaggle Baseline
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03-viz-api-scraper/01-intro-api-twitter.html">
   11. Introduction to APIs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03-viz-api-scraper/02-intro-python-webmining.html">
   12. Web Mining
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03-viz-api-scraper/03-visualization-python-seaborn.html">
   13. Introduction to Seaborn
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03-viz-api-scraper/04-strings-regular-expressions.html">
   14. String Manipulation and Regular Expressions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03-viz-api-scraper/05-features-dummies.html">
   15. Feature Extraction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03-viz-api-scraper/05-features-dummies.html#feature-preprocessing-with-scikit-learn">
   16. Feature Preprocessing with Scikit Learn
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../03-viz-api-scraper/06-matplotlib.html">
   17. MatplotLab
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04-intro-modeling/01-neural-networks.html">
   18. Neural Networks and the Simplist XOR Problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04-intro-modeling/02-train-test-split.html">
   19. Train Test Splits
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04-intro-modeling/03-intro-logistic-knn.html">
   20. Classification with Scikit-learn
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../04-intro-modeling/04-knn.html">
   21. KNN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../05-regression/01-matrix-regression-gradient-decent-python.html">
   22. Linear Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../05-regression/02-regression-boston-housing-python.html">
   23. Boston Housing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../05-regression/03-ridge-lasso-python.html">
   24. Lasso Ridge Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../05-regression/04-stats-models.html">
   25. Regression with Stats-Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../06-unsupervised/01-introduction-pca.html">
   26. Introduction to Principal Component Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../06-unsupervised/02-pca2.html">
   27. In Depth: Principal Component Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../06-unsupervised/03-kmeans.html">
   28. k-Means Clustering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../06-unsupervised/04-covid19.html">
   29. Coronavirus Data Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../07-intro-timeseries/01-time-series.html">
   30. Time Series Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../07-intro-timeseries/02-forcasting-rossman.html">
   31. Panel Data vs Time Series Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../08-intro-nlp/01-titanic-features.html">
   32. Basic Text Feature Creation in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../08-intro-nlp/02-corpus-simple.html">
   33. Introduction to Text Mining in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../08-intro-nlp/03-scikit-learn-text.html">
   34. Bag-of-Words Using Scikit Learn
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../08-intro-nlp/04-what-cooking-python.html">
   35. What’s Cooking in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../08-intro-nlp/05-bag-popcorn-bag-words.html">
   36. Bag of Words
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../08-intro-nlp/07-fastai-imdb.html">
   37. IMDB
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09-deep-learning1/00-neural-networks.html">
   38. Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09-deep-learning1/00-evaluation.html">
   39. Evaluation of Classifiers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09-deep-learning1/01-tensorflow.html">
   40. Tensorflow Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09-deep-learning1/01-tensorflow.html#tensorflow-tabular-data">
   41. Tensorflow Tabular Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09-deep-learning1/01-tensorflow.html#tensorflow-nlp">
   42. Tensorflow NLP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09-deep-learning1/03-pytorch-iris.html">
   43. Revisiting IRIS with PyTorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09-deep-learning1/04-pytorch-explainer.html">
   44. PyTorch Deep Explainer MNIST example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09-deep-learning1/05-pytorch-mnist.html">
   45. PyTorch Deep Explainer MNIST example
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09-deep-learning1/06-regression-bh-pytorch.html">
   46. Revisting Boston Housing with Pytorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09-deep-learning1/07-titanic-fastai.html">
   47. Titanic Fastai
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../09-deep-learning1/08-ludwig.html">
   48. Ludwig
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../10-big-data/01-intro-mapreduce.html">
   49. Introduction to Map Reduce
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../10-big-data/02-intro-spark.html">
   50. Introduction to Spark
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  ASSIGNMENT STARTERS
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../assignments/assignment1/01starter.html">
   Assignment 1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../assignments/assignment2/hm.html">
   Assignment 2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../assignments/assignment3/hm.html">
   Assignment 3
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../assignments/assignment4/hm.html">
   Assignment 4
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../assignments/assignment5/hm.html">
   Assignment 5
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../assignments/assignment6/hm.html">
   Assignment 6
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Deep Learning
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ageron/handson-ml2">
   Hands On Machine Learning with Python
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/fastai/fastbook">
   Fast.ai Book
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://www.tensorflow.org/tutorials">
   Tensorflow Tutorials
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://pytorch.org/tutorials/">
   Pytorch Tutorials
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://www.kaggle.com/learn/intro-to-deep-learning">
   Kaggle Introduction to Deep Learning Course
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  IMPORTANT LINKS
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference external" href="https://lms.rpi.edu/">
   RPI LMS
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://eurl.io/#KijTiY1Sa">
   Webex Teams Discussion
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://eurl.io/#8TF4_qsE9">
   Webex Teams Homework
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://rensselaer.webex.com/meet/kuruzj">
   Prof Kuruzovich Class Link
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://rpi.box.com/s/g3wsswc1gvqxvamkuxee77eb4qugizvj">
   Box File link (Sec01)
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://rensselaer.webex.com/meet/morgat5">
   Prof Morgan Class Link
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://rpi.box.com/s/qdd5wlo58f5ludkxmb4yd17mgnyc0sbh">
   Box File link (Sec02)
   <i class="fas fa-external-link-alt">
   </i>
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/notebooks/book/11_training_deep_neural_networks.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/rpi-techfundamentals/introml_website_fall_2020"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/rpi-techfundamentals/introml_website_fall_2020/issues/new?title=Issue%20on%20page%20%2Fnotebooks/book/11_training_deep_neural_networks.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/rpi-techfundamentals/introml_website_fall_2020/blob/master/site/notebooks/book/11_training_deep_neural_networks.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            
        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><strong>Chapter 11 – Training Deep Neural Networks</strong></p>
<p><em>This notebook contains all the sample code and solutions to the exercises in chapter 11.</em></p>
<table align="left">
  <td>
    <a target="_blank" href="https://colab.research.google.com/github/ageron/handson-ml2/blob/master/11_training_deep_neural_networks.ipynb"><img src="https://www.tensorflow.org/images/colab_logo_32px.png" />Run in Google Colab</a>
  </td>
</table><div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<p>First, let’s import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Python ≥3.5 is required</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="k">assert</span> <span class="n">sys</span><span class="o">.</span><span class="n">version_info</span> <span class="o">&gt;=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="c1"># Scikit-Learn ≥0.20 is required</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="k">assert</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span> <span class="o">&gt;=</span> <span class="s2">&quot;0.20&quot;</span>

<span class="k">try</span><span class="p">:</span>
    <span class="c1"># %tensorflow_version only exists in Colab.</span>
    <span class="o">%</span><span class="n">tensorflow_version</span> <span class="mf">2.</span><span class="n">x</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="c1"># TensorFlow ≥2.0 is required</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="k">assert</span> <span class="n">tf</span><span class="o">.</span><span class="n">__version__</span> <span class="o">&gt;=</span> <span class="s2">&quot;2.0&quot;</span>

<span class="o">%</span><span class="n">load_ext</span> <span class="n">tensorboard</span>

<span class="c1"># Common imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># to make this notebook&#39;s output stable across runs</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># To plot pretty figures</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;axes&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;xtick&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;ytick&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="c1"># Where to save the figures</span>
<span class="n">PROJECT_ROOT_DIR</span> <span class="o">=</span> <span class="s2">&quot;.&quot;</span>
<span class="n">CHAPTER_ID</span> <span class="o">=</span> <span class="s2">&quot;deep&quot;</span>
<span class="n">IMAGES_PATH</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">PROJECT_ROOT_DIR</span><span class="p">,</span> <span class="s2">&quot;images&quot;</span><span class="p">,</span> <span class="n">CHAPTER_ID</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">IMAGES_PATH</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">save_fig</span><span class="p">(</span><span class="n">fig_id</span><span class="p">,</span> <span class="n">tight_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fig_extension</span><span class="o">=</span><span class="s2">&quot;png&quot;</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="mi">300</span><span class="p">):</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">IMAGES_PATH</span><span class="p">,</span> <span class="n">fig_id</span> <span class="o">+</span> <span class="s2">&quot;.&quot;</span> <span class="o">+</span> <span class="n">fig_extension</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Saving figure&quot;</span><span class="p">,</span> <span class="n">fig_id</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">tight_layout</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="n">fig_extension</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="n">resolution</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="vanishing-exploding-gradients-problem">
<h1>Vanishing/Exploding Gradients Problem<a class="headerlink" href="#vanishing-exploding-gradients-problem" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">logit</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;k-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">],</span> <span class="s1">&#39;k-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="o">/</span><span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="o">/</span><span class="mi">4</span><span class="p">],</span> <span class="s1">&#39;g--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">logit</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="s2">&quot;b-&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">props</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">shrink</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;Saturating&#39;</span><span class="p">,</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">),</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">arrowprops</span><span class="o">=</span><span class="n">props</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;Saturating&#39;</span><span class="p">,</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">arrowprops</span><span class="o">=</span><span class="n">props</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;Linear&#39;</span><span class="p">,</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">arrowprops</span><span class="o">=</span><span class="n">props</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Sigmoid activation function&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">])</span>

<span class="n">save_fig</span><span class="p">(</span><span class="s2">&quot;sigmoid_saturation_plot&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Saving figure sigmoid_saturation_plot
</pre></div>
</div>
<img alt="../../_images/11_training_deep_neural_networks_8_1.png" src="../../_images/11_training_deep_neural_networks_8_1.png" />
</div>
</div>
<div class="section" id="xavier-and-he-initialization">
<h2>Xavier and He Initialization<a class="headerlink" href="#xavier-and-he-initialization" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">name</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>[&#39;Constant&#39;,
 &#39;GlorotNormal&#39;,
 &#39;GlorotUniform&#39;,
 &#39;Identity&#39;,
 &#39;Initializer&#39;,
 &#39;Ones&#39;,
 &#39;Orthogonal&#39;,
 &#39;RandomNormal&#39;,
 &#39;RandomUniform&#39;,
 &#39;TruncatedNormal&#39;,
 &#39;VarianceScaling&#39;,
 &#39;Zeros&#39;,
 &#39;constant&#39;,
 &#39;deserialize&#39;,
 &#39;get&#39;,
 &#39;glorot_normal&#39;,
 &#39;glorot_uniform&#39;,
 &#39;he_normal&#39;,
 &#39;he_uniform&#39;,
 &#39;identity&#39;,
 &#39;lecun_normal&#39;,
 &#39;lecun_uniform&#39;,
 &#39;ones&#39;,
 &#39;orthogonal&#39;,
 &#39;serialize&#39;,
 &#39;zeros&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;he_normal&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.layers.core.Dense at 0x7fc228455278&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">init</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">VarianceScaling</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">2.</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fan_avg&#39;</span><span class="p">,</span>
                                          <span class="n">distribution</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">)</span>
<span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">init</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.layers.core.Dense at 0x7fc25bba6e10&gt;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="nonsaturating-activation-functions">
<h2>Nonsaturating Activation Functions<a class="headerlink" href="#nonsaturating-activation-functions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="leaky-relu">
<h3>Leaky ReLU<a class="headerlink" href="#leaky-relu" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">leaky_relu</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">alpha</span><span class="o">*</span><span class="n">z</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">leaky_relu</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">),</span> <span class="s2">&quot;b-&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;k-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">4.2</span><span class="p">],</span> <span class="s1">&#39;k-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">props</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">shrink</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;Leak&#39;</span><span class="p">,</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">3.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">),</span> <span class="n">arrowprops</span><span class="o">=</span><span class="n">props</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Leaky ReLU activation function&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">4.2</span><span class="p">])</span>

<span class="n">save_fig</span><span class="p">(</span><span class="s2">&quot;leaky_relu_plot&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Saving figure leaky_relu_plot
</pre></div>
</div>
<img alt="../../_images/11_training_deep_neural_networks_16_1.png" src="../../_images/11_training_deep_neural_networks_16_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">m</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">activations</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">m</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>[&#39;deserialize&#39;,
 &#39;elu&#39;,
 &#39;exponential&#39;,
 &#39;get&#39;,
 &#39;hard_sigmoid&#39;,
 &#39;linear&#39;,
 &#39;relu&#39;,
 &#39;selu&#39;,
 &#39;serialize&#39;,
 &#39;sigmoid&#39;,
 &#39;softmax&#39;,
 &#39;softplus&#39;,
 &#39;softsign&#39;,
 &#39;tanh&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">m</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span> <span class="k">if</span> <span class="s2">&quot;relu&quot;</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">lower</span><span class="p">()]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>[&#39;LeakyReLU&#39;, &#39;PReLU&#39;, &#39;ReLU&#39;, &#39;ThresholdedReLU&#39;]
</pre></div>
</div>
</div>
</div>
<p>Let’s train a neural network on Fashion MNIST using the Leaky ReLU:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">X_train_full</span><span class="p">,</span> <span class="n">y_train_full</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">fashion_mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">X_train_full</span> <span class="o">=</span> <span class="n">X_train_full</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span> <span class="o">/</span> <span class="mf">255.0</span>
<span class="n">X_valid</span><span class="p">,</span> <span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train_full</span><span class="p">[:</span><span class="mi">5000</span><span class="p">],</span> <span class="n">X_train_full</span><span class="p">[</span><span class="mi">5000</span><span class="p">:]</span>
<span class="n">y_valid</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train_full</span><span class="p">[:</span><span class="mi">5000</span><span class="p">],</span> <span class="n">y_train_full</span><span class="p">[</span><span class="mi">5000</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;he_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;he_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples, validate on 5000 samples
Epoch 1/10
55000/55000 [==============================] - 2s 41us/sample - loss: 1.2810 - accuracy: 0.6205 - val_loss: 0.8869 - val_accuracy: 0.7160
Epoch 2/10
55000/55000 [==============================] - 2s 38us/sample - loss: 0.7952 - accuracy: 0.7369 - val_loss: 0.7132 - val_accuracy: 0.7626
Epoch 3/10
55000/55000 [==============================] - 2s 37us/sample - loss: 0.6817 - accuracy: 0.7726 - val_loss: 0.6385 - val_accuracy: 0.7894
Epoch 4/10
55000/55000 [==============================] - 2s 37us/sample - loss: 0.6219 - accuracy: 0.7942 - val_loss: 0.5931 - val_accuracy: 0.8016
Epoch 5/10
55000/55000 [==============================] - 2s 38us/sample - loss: 0.5830 - accuracy: 0.8074 - val_loss: 0.5607 - val_accuracy: 0.8170
Epoch 6/10
55000/55000 [==============================] - 2s 38us/sample - loss: 0.5552 - accuracy: 0.8172 - val_loss: 0.5355 - val_accuracy: 0.8238
Epoch 7/10
55000/55000 [==============================] - 2s 40us/sample - loss: 0.5339 - accuracy: 0.8226 - val_loss: 0.5166 - val_accuracy: 0.8298
Epoch 8/10
55000/55000 [==============================] - 2s 43us/sample - loss: 0.5173 - accuracy: 0.8262 - val_loss: 0.5043 - val_accuracy: 0.8356
Epoch 9/10
55000/55000 [==============================] - 2s 38us/sample - loss: 0.5039 - accuracy: 0.8306 - val_loss: 0.4889 - val_accuracy: 0.8384
Epoch 10/10
55000/55000 [==============================] - 2s 38us/sample - loss: 0.4923 - accuracy: 0.8333 - val_loss: 0.4816 - val_accuracy: 0.8394
</pre></div>
</div>
</div>
</div>
<p>Now let’s try PReLU:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;he_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;he_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples, validate on 5000 samples
Epoch 1/10
55000/55000 [==============================] - 3s 47us/sample - loss: 1.3452 - accuracy: 0.6203 - val_loss: 0.9241 - val_accuracy: 0.7170
Epoch 2/10
55000/55000 [==============================] - 2s 41us/sample - loss: 0.8196 - accuracy: 0.7364 - val_loss: 0.7314 - val_accuracy: 0.7600
Epoch 3/10
55000/55000 [==============================] - 2s 41us/sample - loss: 0.6970 - accuracy: 0.7701 - val_loss: 0.6517 - val_accuracy: 0.7880
Epoch 4/10
55000/55000 [==============================] - 2s 40us/sample - loss: 0.6333 - accuracy: 0.7914 - val_loss: 0.6032 - val_accuracy: 0.8050
Epoch 5/10
55000/55000 [==============================] - 2s 41us/sample - loss: 0.5916 - accuracy: 0.8049 - val_loss: 0.5689 - val_accuracy: 0.8162
Epoch 6/10
55000/55000 [==============================] - 2s 40us/sample - loss: 0.5619 - accuracy: 0.8143 - val_loss: 0.5416 - val_accuracy: 0.8222
Epoch 7/10
55000/55000 [==============================] - 2s 40us/sample - loss: 0.5391 - accuracy: 0.8208 - val_loss: 0.5213 - val_accuracy: 0.8300
Epoch 8/10
55000/55000 [==============================] - 2s 41us/sample - loss: 0.5214 - accuracy: 0.8258 - val_loss: 0.5075 - val_accuracy: 0.8348
Epoch 9/10
55000/55000 [==============================] - 2s 42us/sample - loss: 0.5070 - accuracy: 0.8287 - val_loss: 0.4917 - val_accuracy: 0.8380
Epoch 10/10
55000/55000 [==============================] - 2s 40us/sample - loss: 0.4946 - accuracy: 0.8322 - val_loss: 0.4839 - val_accuracy: 0.8378
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="elu">
<h3>ELU<a class="headerlink" href="#elu" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">elu</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">z</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="n">z</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">elu</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="s2">&quot;b-&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;k-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">2.2</span><span class="p">,</span> <span class="mf">3.2</span><span class="p">],</span> <span class="s1">&#39;k-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;ELU activation function ($\alpha=1$)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.2</span><span class="p">,</span> <span class="mf">3.2</span><span class="p">])</span>

<span class="n">save_fig</span><span class="p">(</span><span class="s2">&quot;elu_plot&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Saving figure elu_plot
</pre></div>
</div>
<img alt="../../_images/11_training_deep_neural_networks_30_1.png" src="../../_images/11_training_deep_neural_networks_30_1.png" />
</div>
</div>
<p>Implementing ELU in TensorFlow is trivial, just specify the activation function when building each layer:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;elu&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.layers.core.Dense at 0x7fc208500a90&gt;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="selu">
<h3>SELU<a class="headerlink" href="#selu" title="Permalink to this headline">¶</a></h3>
<p>This activation function was proposed in this <a class="reference external" href="https://arxiv.org/pdf/1706.02515.pdf">great paper</a> by Günter Klambauer, Thomas Unterthiner and Andreas Mayr, published in June 2017. During training, a neural network composed exclusively of a stack of dense layers using the SELU activation function and LeCun initialization will self-normalize: the output of each layer will tend to preserve the same mean and variance during training, which solves the vanishing/exploding gradients problem. As a result, this activation function outperforms the other activation functions very significantly for such neural nets, so you should really try it out. Unfortunately, the self-normalizing property of the SELU activation function is easily broken: you cannot use ℓ<sub>1</sub> or ℓ<sub>2</sub> regularization, regular dropout, max-norm, skip connections or other non-sequential topologies (so recurrent neural networks won’t self-normalize). However, in practice it works quite well with sequential CNNs. If you break self-normalization, SELU will not necessarily outperform other activation functions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">erfc</span>

<span class="c1"># alpha and scale to self normalize with mean 0 and standard deviation 1</span>
<span class="c1"># (see equation 14 in the paper):</span>
<span class="n">alpha_0_1</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">erfc</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">scale_0_1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">erfc</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">e</span><span class="p">))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">erfc</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">e</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">erfc</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">e</span> <span class="o">-</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="mi">2</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span><span class="o">*</span><span class="n">erfc</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">e</span><span class="p">)</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">selu</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale_0_1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha_0_1</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">elu</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">selu</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="s2">&quot;b-&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;k-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.758</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.758</span><span class="p">],</span> <span class="s1">&#39;k--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">2.2</span><span class="p">,</span> <span class="mf">3.2</span><span class="p">],</span> <span class="s1">&#39;k-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;SELU activation function&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.2</span><span class="p">,</span> <span class="mf">3.2</span><span class="p">])</span>

<span class="n">save_fig</span><span class="p">(</span><span class="s2">&quot;selu_plot&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Saving figure selu_plot
</pre></div>
</div>
<img alt="../../_images/11_training_deep_neural_networks_37_1.png" src="../../_images/11_training_deep_neural_networks_37_1.png" />
</div>
</div>
<p>By default, the SELU hyperparameters (<code class="docutils literal notranslate"><span class="pre">scale</span></code> and <code class="docutils literal notranslate"><span class="pre">alpha</span></code>) are tuned in such a way that the mean output of each neuron remains close to 0, and the standard deviation remains close to 1 (assuming the inputs are standardized with mean 0 and standard deviation 1 too). Using this activation function, even a 1,000 layer deep neural network preserves roughly mean 0 and standard deviation 1 across all layers, avoiding the exploding/vanishing gradients problem:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span> <span class="c1"># standardized inputs</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">scale</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="mi">100</span><span class="p">))</span> <span class="c1"># LeCun initialization</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">selu</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">W</span><span class="p">))</span>
    <span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">stds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">layer</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Layer </span><span class="si">{}</span><span class="s2">: mean </span><span class="si">{:.2f}</span><span class="s2">, std deviation </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">means</span><span class="p">,</span> <span class="n">stds</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Layer 0: mean -0.00, std deviation 1.00
Layer 100: mean 0.02, std deviation 0.96
Layer 200: mean 0.01, std deviation 0.90
Layer 300: mean -0.02, std deviation 0.92
Layer 400: mean 0.05, std deviation 0.89
Layer 500: mean 0.01, std deviation 0.93
Layer 600: mean 0.02, std deviation 0.92
Layer 700: mean -0.02, std deviation 0.90
Layer 800: mean 0.05, std deviation 0.83
Layer 900: mean 0.02, std deviation 1.00
</pre></div>
</div>
</div>
</div>
<p>Using SELU is easy:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span>
                   <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.layers.core.Dense at 0x7fc228758668&gt;
</pre></div>
</div>
</div>
</div>
<p>Let’s create a neural net for Fashion MNIST with 100 hidden layers, using the SELU activation function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span>
                             <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">))</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">99</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span>
                                 <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s train it. Do not forget to scale the inputs to mean 0 and standard deviation 1:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pixel_means</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pixel_stds</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_train</span> <span class="o">-</span> <span class="n">pixel_means</span><span class="p">)</span> <span class="o">/</span> <span class="n">pixel_stds</span>
<span class="n">X_valid_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_valid</span> <span class="o">-</span> <span class="n">pixel_means</span><span class="p">)</span> <span class="o">/</span> <span class="n">pixel_stds</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_test</span> <span class="o">-</span> <span class="n">pixel_means</span><span class="p">)</span> <span class="o">/</span> <span class="n">pixel_stds</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples, validate on 5000 samples
Epoch 1/5
55000/55000 [==============================] - 13s 238us/sample - loss: 1.1277 - accuracy: 0.5573 - val_loss: 0.8152 - val_accuracy: 0.6700
Epoch 2/5
55000/55000 [==============================] - 11s 198us/sample - loss: 0.6935 - accuracy: 0.7383 - val_loss: 0.5806 - val_accuracy: 0.7928
Epoch 3/5
55000/55000 [==============================] - 11s 196us/sample - loss: 0.5871 - accuracy: 0.7865 - val_loss: 0.6876 - val_accuracy: 0.7462
Epoch 4/5
55000/55000 [==============================] - 11s 199us/sample - loss: 0.5281 - accuracy: 0.8134 - val_loss: 0.5236 - val_accuracy: 0.8230
Epoch 5/5
55000/55000 [==============================] - 11s 201us/sample - loss: 0.4824 - accuracy: 0.8327 - val_loss: 0.5201 - val_accuracy: 0.8312
</pre></div>
</div>
</div>
</div>
<p>Now look at what happens if we try to use the ReLU activation function instead:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;he_normal&quot;</span><span class="p">))</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">99</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;he_normal&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples, validate on 5000 samples
Epoch 1/5
55000/55000 [==============================] - 12s 213us/sample - loss: 1.7518 - accuracy: 0.2797 - val_loss: 1.2328 - val_accuracy: 0.4720
Epoch 2/5
55000/55000 [==============================] - 10s 177us/sample - loss: 1.1922 - accuracy: 0.4982 - val_loss: 1.0247 - val_accuracy: 0.5354
Epoch 3/5
55000/55000 [==============================] - 10s 178us/sample - loss: 0.9390 - accuracy: 0.6180 - val_loss: 1.0809 - val_accuracy: 0.5118
Epoch 4/5
55000/55000 [==============================] - 10s 178us/sample - loss: 0.7787 - accuracy: 0.6937 - val_loss: 0.7067 - val_accuracy: 0.7344
Epoch 5/5
55000/55000 [==============================] - 10s 180us/sample - loss: 0.7465 - accuracy: 0.7122 - val_loss: 0.9720 - val_accuracy: 0.5702
</pre></div>
</div>
</div>
</div>
<p>Not great at all, we suffered from the vanishing/exploding gradients problem.</p>
</div>
</div>
</div>
<div class="section" id="batch-normalization">
<h1>Batch Normalization<a class="headerlink" href="#batch-normalization" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Model: &quot;sequential_4&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_4 (Flatten)          (None, 784)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 784)               3136      
_________________________________________________________________
dense_212 (Dense)            (None, 300)               235500    
_________________________________________________________________
batch_normalization_1 (Batch (None, 300)               1200      
_________________________________________________________________
dense_213 (Dense)            (None, 100)               30100     
_________________________________________________________________
batch_normalization_2 (Batch (None, 100)               400       
_________________________________________________________________
dense_214 (Dense)            (None, 10)                1010      
=================================================================
Total params: 271,346
Trainable params: 268,978
Non-trainable params: 2,368
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bn1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="p">[(</span><span class="n">var</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">var</span><span class="o">.</span><span class="n">trainable</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">bn1</span><span class="o">.</span><span class="n">variables</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>[(&#39;batch_normalization/gamma:0&#39;, True),
 (&#39;batch_normalization/beta:0&#39;, True),
 (&#39;batch_normalization/moving_mean:0&#39;, False),
 (&#39;batch_normalization/moving_variance:0&#39;, False)]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">bn1</span><span class="o">.</span><span class="n">updates</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>[&lt;tf.Operation &#39;cond/Identity&#39; type=Identity&gt;,
 &lt;tf.Operation &#39;cond_1/Identity&#39; type=Identity&gt;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples, validate on 5000 samples
Epoch 1/10
55000/55000 [==============================] - 3s 63us/sample - loss: 0.8760 - accuracy: 0.7122 - val_loss: 0.5509 - val_accuracy: 0.8224
Epoch 2/10
55000/55000 [==============================] - 3s 54us/sample - loss: 0.5737 - accuracy: 0.8039 - val_loss: 0.4723 - val_accuracy: 0.8460
Epoch 3/10
55000/55000 [==============================] - 3s 54us/sample - loss: 0.5143 - accuracy: 0.8231 - val_loss: 0.4376 - val_accuracy: 0.8570
Epoch 4/10
55000/55000 [==============================] - 3s 55us/sample - loss: 0.4826 - accuracy: 0.8333 - val_loss: 0.4135 - val_accuracy: 0.8638
Epoch 5/10
55000/55000 [==============================] - 3s 54us/sample - loss: 0.4571 - accuracy: 0.8415 - val_loss: 0.3990 - val_accuracy: 0.8654
Epoch 6/10
55000/55000 [==============================] - 3s 53us/sample - loss: 0.4432 - accuracy: 0.8456 - val_loss: 0.3870 - val_accuracy: 0.8710
Epoch 7/10
55000/55000 [==============================] - 3s 56us/sample - loss: 0.4255 - accuracy: 0.8515 - val_loss: 0.3782 - val_accuracy: 0.8698
Epoch 8/10
55000/55000 [==============================] - 3s 54us/sample - loss: 0.4150 - accuracy: 0.8536 - val_loss: 0.3708 - val_accuracy: 0.8758
Epoch 9/10
55000/55000 [==============================] - 3s 54us/sample - loss: 0.4016 - accuracy: 0.8596 - val_loss: 0.3634 - val_accuracy: 0.8750
Epoch 10/10
55000/55000 [==============================] - 3s 55us/sample - loss: 0.3915 - accuracy: 0.8629 - val_loss: 0.3601 - val_accuracy: 0.8758
</pre></div>
</div>
</div>
</div>
<p>Sometimes applying BN before the activation function works better (there’s a debate on this topic). Moreover, the layer before a <code class="docutils literal notranslate"><span class="pre">BatchNormalization</span></code> layer does not need to have bias terms, since the <code class="docutils literal notranslate"><span class="pre">BatchNormalization</span></code> layer some as well, it would be a waste of parameters, so you can set <code class="docutils literal notranslate"><span class="pre">use_bias=False</span></code> when creating those layers:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;relu&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples, validate on 5000 samples
Epoch 1/10
55000/55000 [==============================] - 4s 64us/sample - loss: 0.8656 - accuracy: 0.7094 - val_loss: 0.5650 - val_accuracy: 0.8098
Epoch 2/10
55000/55000 [==============================] - 3s 55us/sample - loss: 0.5766 - accuracy: 0.8018 - val_loss: 0.4834 - val_accuracy: 0.8358
Epoch 3/10
55000/55000 [==============================] - 3s 55us/sample - loss: 0.5184 - accuracy: 0.8216 - val_loss: 0.4461 - val_accuracy: 0.8470
Epoch 4/10
55000/55000 [==============================] - 3s 55us/sample - loss: 0.4852 - accuracy: 0.8314 - val_loss: 0.4226 - val_accuracy: 0.8558
Epoch 5/10
55000/55000 [==============================] - 3s 54us/sample - loss: 0.4579 - accuracy: 0.8399 - val_loss: 0.4086 - val_accuracy: 0.8604
Epoch 6/10
55000/55000 [==============================] - 3s 55us/sample - loss: 0.4406 - accuracy: 0.8457 - val_loss: 0.3974 - val_accuracy: 0.8640
Epoch 7/10
55000/55000 [==============================] - 3s 55us/sample - loss: 0.4263 - accuracy: 0.8498 - val_loss: 0.3883 - val_accuracy: 0.8676
Epoch 8/10
55000/55000 [==============================] - 3s 55us/sample - loss: 0.4152 - accuracy: 0.8530 - val_loss: 0.3803 - val_accuracy: 0.8682
Epoch 9/10
55000/55000 [==============================] - 3s 55us/sample - loss: 0.4032 - accuracy: 0.8564 - val_loss: 0.3738 - val_accuracy: 0.8718
Epoch 10/10
55000/55000 [==============================] - 3s 55us/sample - loss: 0.3937 - accuracy: 0.8623 - val_loss: 0.3690 - val_accuracy: 0.8732
</pre></div>
</div>
</div>
</div>
<div class="section" id="gradient-clipping">
<h2>Gradient Clipping<a class="headerlink" href="#gradient-clipping" title="Permalink to this headline">¶</a></h2>
<p>All Keras optimizers accept <code class="docutils literal notranslate"><span class="pre">clipnorm</span></code> or <code class="docutils literal notranslate"><span class="pre">clipvalue</span></code> arguments:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">clipvalue</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">clipnorm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="reusing-pretrained-layers">
<h2>Reusing Pretrained Layers<a class="headerlink" href="#reusing-pretrained-layers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="reusing-a-keras-model">
<h3>Reusing a Keras model<a class="headerlink" href="#reusing-a-keras-model" title="Permalink to this headline">¶</a></h3>
<p>Let’s split the fashion MNIST training set in two:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">X_train_A</span></code>: all images of all items except for sandals and shirts (classes 5 and 6).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">X_train_B</span></code>: a much smaller training set of just the first 200 images of sandals or shirts.</p></li>
</ul>
<p>The validation set and the test set are also split this way, but without restricting the number of images.</p>
<p>We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (sneakers, ankle boots, coats, t-shirts, etc.) are somewhat similar to classes in set B (sandals and shirts). However, since we are using <code class="docutils literal notranslate"><span class="pre">Dense</span></code> layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image, as we will see in the CNN chapter).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">split_dataset</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">y_5_or_6</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">5</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">6</span><span class="p">)</span> <span class="c1"># sandals or shirts</span>
    <span class="n">y_A</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="o">~</span><span class="n">y_5_or_6</span><span class="p">]</span>
    <span class="n">y_A</span><span class="p">[</span><span class="n">y_A</span> <span class="o">&gt;</span> <span class="mi">6</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">2</span> <span class="c1"># class indices 7, 8, 9 should be moved to 5, 6, 7</span>
    <span class="n">y_B</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">y_5_or_6</span><span class="p">]</span> <span class="o">==</span> <span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># binary classification task: is it a shirt (class 6)?</span>
    <span class="k">return</span> <span class="p">((</span><span class="n">X</span><span class="p">[</span><span class="o">~</span><span class="n">y_5_or_6</span><span class="p">],</span> <span class="n">y_A</span><span class="p">),</span>
            <span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">y_5_or_6</span><span class="p">],</span> <span class="n">y_B</span><span class="p">))</span>

<span class="p">(</span><span class="n">X_train_A</span><span class="p">,</span> <span class="n">y_train_A</span><span class="p">),</span> <span class="p">(</span><span class="n">X_train_B</span><span class="p">,</span> <span class="n">y_train_B</span><span class="p">)</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="p">(</span><span class="n">X_valid_A</span><span class="p">,</span> <span class="n">y_valid_A</span><span class="p">),</span> <span class="p">(</span><span class="n">X_valid_B</span><span class="p">,</span> <span class="n">y_valid_B</span><span class="p">)</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
<span class="p">(</span><span class="n">X_test_A</span><span class="p">,</span> <span class="n">y_test_A</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test_B</span><span class="p">,</span> <span class="n">y_test_B</span><span class="p">)</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">X_train_B</span> <span class="o">=</span> <span class="n">X_train_B</span><span class="p">[:</span><span class="mi">200</span><span class="p">]</span>
<span class="n">y_train_B</span> <span class="o">=</span> <span class="n">y_train_B</span><span class="p">[:</span><span class="mi">200</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_A</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>(43986, 28, 28)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_B</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>(200, 28, 28)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y_train_A</span><span class="p">[:</span><span class="mi">30</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([4, 0, 5, 7, 7, 7, 4, 4, 3, 4, 0, 1, 6, 3, 4, 3, 2, 6, 5, 3, 4, 5,
       1, 3, 4, 2, 0, 6, 7, 1], dtype=uint8)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y_train_B</span><span class="p">[:</span><span class="mi">30</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_A</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model_A</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]))</span>
<span class="k">for</span> <span class="n">n_hidden</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">):</span>
    <span class="n">model_A</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">))</span>
<span class="n">model_A</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_A</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span>
                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model_A</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_A</span><span class="p">,</span> <span class="n">y_train_A</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_A</span><span class="p">,</span> <span class="n">y_valid_A</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 43986 samples, validate on 4014 samples
Epoch 1/20
43986/43986 [==============================] - 2s 49us/sample - loss: 0.5902 - accuracy: 0.8131 - val_loss: 0.3784 - val_accuracy: 0.8692
Epoch 2/20
43986/43986 [==============================] - 2s 43us/sample - loss: 0.3517 - accuracy: 0.8784 - val_loss: 0.3369 - val_accuracy: 0.8832
Epoch 3/20
43986/43986 [==============================] - 2s 43us/sample - loss: 0.3163 - accuracy: 0.8896 - val_loss: 0.3017 - val_accuracy: 0.8959
Epoch 4/20
43986/43986 [==============================] - 2s 43us/sample - loss: 0.2969 - accuracy: 0.8972 - val_loss: 0.2912 - val_accuracy: 0.9028
Epoch 5/20
43986/43986 [==============================] - 2s 45us/sample - loss: 0.2831 - accuracy: 0.9027 - val_loss: 0.2816 - val_accuracy: 0.9018
Epoch 6/20
43986/43986 [==============================] - 2s 44us/sample - loss: 0.2725 - accuracy: 0.9066 - val_loss: 0.2737 - val_accuracy: 0.9071
Epoch 7/20
43986/43986 [==============================] - 2s 43us/sample - loss: 0.2644 - accuracy: 0.9095 - val_loss: 0.2652 - val_accuracy: 0.9091
Epoch 8/20
43986/43986 [==============================] - 2s 44us/sample - loss: 0.2577 - accuracy: 0.9119 - val_loss: 0.2580 - val_accuracy: 0.9126
Epoch 9/20
43986/43986 [==============================] - 2s 43us/sample - loss: 0.2516 - accuracy: 0.9137 - val_loss: 0.2582 - val_accuracy: 0.9136
Epoch 10/20
43986/43986 [==============================] - 2s 44us/sample - loss: 0.2466 - accuracy: 0.9153 - val_loss: 0.2522 - val_accuracy: 0.9153
Epoch 11/20
43986/43986 [==============================] - 2s 44us/sample - loss: 0.2420 - accuracy: 0.9178 - val_loss: 0.2489 - val_accuracy: 0.9168
Epoch 12/20
43986/43986 [==============================] - 2s 43us/sample - loss: 0.2381 - accuracy: 0.9192 - val_loss: 0.2457 - val_accuracy: 0.9175
Epoch 13/20
43986/43986 [==============================] - 2s 44us/sample - loss: 0.2347 - accuracy: 0.9197 - val_loss: 0.2449 - val_accuracy: 0.9198
Epoch 14/20
43986/43986 [==============================] - 2s 44us/sample - loss: 0.2312 - accuracy: 0.9206 - val_loss: 0.2431 - val_accuracy: 0.9170
Epoch 15/20
43986/43986 [==============================] - 2s 44us/sample - loss: 0.2282 - accuracy: 0.9219 - val_loss: 0.2430 - val_accuracy: 0.9180
Epoch 16/20
43986/43986 [==============================] - 2s 44us/sample - loss: 0.2255 - accuracy: 0.9229 - val_loss: 0.2411 - val_accuracy: 0.9150
Epoch 17/20
43986/43986 [==============================] - 2s 43us/sample - loss: 0.2228 - accuracy: 0.9229 - val_loss: 0.2370 - val_accuracy: 0.9178
Epoch 18/20
43986/43986 [==============================] - 2s 43us/sample - loss: 0.2202 - accuracy: 0.9242 - val_loss: 0.2433 - val_accuracy: 0.9170
Epoch 19/20
43986/43986 [==============================] - 2s 43us/sample - loss: 0.2177 - accuracy: 0.9252 - val_loss: 0.2605 - val_accuracy: 0.9043
Epoch 20/20
43986/43986 [==============================] - 2s 43us/sample - loss: 0.2158 - accuracy: 0.9265 - val_loss: 0.2328 - val_accuracy: 0.9205
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_A</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;my_model_A.h5&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_B</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model_B</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]))</span>
<span class="k">for</span> <span class="n">n_hidden</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">):</span>
    <span class="n">model_B</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">))</span>
<span class="n">model_B</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_B</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;binary_crossentropy&quot;</span><span class="p">,</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span>
                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model_B</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_B</span><span class="p">,</span> <span class="n">y_train_B</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                      <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_B</span><span class="p">,</span> <span class="n">y_valid_B</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 200 samples, validate on 986 samples
Epoch 1/20
200/200 [==============================] - 0s 2ms/sample - loss: 0.9509 - accuracy: 0.4800 - val_loss: 0.6533 - val_accuracy: 0.5568
Epoch 2/20
200/200 [==============================] - 0s 202us/sample - loss: 0.5837 - accuracy: 0.7100 - val_loss: 0.4825 - val_accuracy: 0.8479
Epoch 3/20
200/200 [==============================] - 0s 206us/sample - loss: 0.4527 - accuracy: 0.8750 - val_loss: 0.4097 - val_accuracy: 0.8945
Epoch 4/20
200/200 [==============================] - 0s 219us/sample - loss: 0.3869 - accuracy: 0.9050 - val_loss: 0.3630 - val_accuracy: 0.9209
Epoch 5/20
200/200 [==============================] - 0s 224us/sample - loss: 0.3404 - accuracy: 0.9300 - val_loss: 0.3302 - val_accuracy: 0.9280
Epoch 6/20
200/200 [==============================] - 0s 225us/sample - loss: 0.3073 - accuracy: 0.9350 - val_loss: 0.3026 - val_accuracy: 0.9381
Epoch 7/20
200/200 [==============================] - 0s 228us/sample - loss: 0.2797 - accuracy: 0.9400 - val_loss: 0.2790 - val_accuracy: 0.9452
Epoch 8/20
200/200 [==============================] - 0s 221us/sample - loss: 0.2554 - accuracy: 0.9450 - val_loss: 0.2595 - val_accuracy: 0.9473
Epoch 9/20
200/200 [==============================] - 0s 232us/sample - loss: 0.2355 - accuracy: 0.9600 - val_loss: 0.2439 - val_accuracy: 0.9493
Epoch 10/20
200/200 [==============================] - 0s 220us/sample - loss: 0.2187 - accuracy: 0.9650 - val_loss: 0.2293 - val_accuracy: 0.9523
Epoch 11/20
200/200 [==============================] - 0s 210us/sample - loss: 0.2041 - accuracy: 0.9650 - val_loss: 0.2162 - val_accuracy: 0.9544
Epoch 12/20
200/200 [==============================] - 0s 223us/sample - loss: 0.1906 - accuracy: 0.9650 - val_loss: 0.2049 - val_accuracy: 0.9574
Epoch 13/20
200/200 [==============================] - 0s 211us/sample - loss: 0.1791 - accuracy: 0.9700 - val_loss: 0.1946 - val_accuracy: 0.9594
Epoch 14/20
200/200 [==============================] - 0s 214us/sample - loss: 0.1686 - accuracy: 0.9750 - val_loss: 0.1856 - val_accuracy: 0.9615
Epoch 15/20
200/200 [==============================] - 0s 203us/sample - loss: 0.1591 - accuracy: 0.9750 - val_loss: 0.1765 - val_accuracy: 0.9655
Epoch 16/20
200/200 [==============================] - 0s 222us/sample - loss: 0.1502 - accuracy: 0.9900 - val_loss: 0.1695 - val_accuracy: 0.9655
Epoch 17/20
200/200 [==============================] - 0s 235us/sample - loss: 0.1424 - accuracy: 0.9900 - val_loss: 0.1624 - val_accuracy: 0.9686
Epoch 18/20
200/200 [==============================] - 0s 224us/sample - loss: 0.1351 - accuracy: 0.9900 - val_loss: 0.1567 - val_accuracy: 0.9686
Epoch 19/20
200/200 [==============================] - 0s 207us/sample - loss: 0.1290 - accuracy: 0.9900 - val_loss: 0.1513 - val_accuracy: 0.9696
Epoch 20/20
200/200 [==============================] - 0s 213us/sample - loss: 0.1229 - accuracy: 0.9900 - val_loss: 0.1450 - val_accuracy: 0.9696
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Model: &quot;sequential_5&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_5 (Flatten)          (None, 784)               0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 784)               3136      
_________________________________________________________________
dense_215 (Dense)            (None, 300)               235200    
_________________________________________________________________
batch_normalization_4 (Batch (None, 300)               1200      
_________________________________________________________________
activation (Activation)      (None, 300)               0         
_________________________________________________________________
dense_216 (Dense)            (None, 100)               30000     
_________________________________________________________________
activation_1 (Activation)    (None, 100)               0         
_________________________________________________________________
batch_normalization_5 (Batch (None, 100)               400       
_________________________________________________________________
dense_217 (Dense)            (None, 10)                1010      
=================================================================
Total params: 270,946
Trainable params: 268,578
Non-trainable params: 2,368
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_A</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;my_model_A.h5&quot;</span><span class="p">)</span>
<span class="n">model_B_on_A</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">model_A</span><span class="o">.</span><span class="n">layers</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">model_B_on_A</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_A_clone</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">clone_model</span><span class="p">(</span><span class="n">model_A</span><span class="p">)</span>
<span class="n">model_A_clone</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">model_A</span><span class="o">.</span><span class="n">get_weights</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model_B_on_A</span><span class="o">.</span><span class="n">layers</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">model_B_on_A</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;binary_crossentropy&quot;</span><span class="p">,</span>
                     <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span>
                     <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model_B_on_A</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_B</span><span class="p">,</span> <span class="n">y_train_B</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                           <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_B</span><span class="p">,</span> <span class="n">y_valid_B</span><span class="p">))</span>

<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model_B_on_A</span><span class="o">.</span><span class="n">layers</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">model_B_on_A</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;binary_crossentropy&quot;</span><span class="p">,</span>
                     <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span>
                     <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model_B_on_A</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_B</span><span class="p">,</span> <span class="n">y_train_B</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
                           <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_B</span><span class="p">,</span> <span class="n">y_valid_B</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 200 samples, validate on 986 samples
Epoch 1/4
200/200 [==============================] - 0s 2ms/sample - loss: 0.5619 - accuracy: 0.6650 - val_loss: 0.5669 - val_accuracy: 0.6531
Epoch 2/4
200/200 [==============================] - 0s 208us/sample - loss: 0.5249 - accuracy: 0.7200 - val_loss: 0.5337 - val_accuracy: 0.6957
Epoch 3/4
200/200 [==============================] - 0s 200us/sample - loss: 0.4923 - accuracy: 0.7400 - val_loss: 0.5039 - val_accuracy: 0.7211
Epoch 4/4
200/200 [==============================] - 0s 214us/sample - loss: 0.4630 - accuracy: 0.7550 - val_loss: 0.4773 - val_accuracy: 0.7383
Train on 200 samples, validate on 986 samples
Epoch 1/16
200/200 [==============================] - 0s 2ms/sample - loss: 0.3864 - accuracy: 0.8200 - val_loss: 0.3357 - val_accuracy: 0.8661
Epoch 2/16
200/200 [==============================] - 0s 207us/sample - loss: 0.2701 - accuracy: 0.9350 - val_loss: 0.2608 - val_accuracy: 0.9249
Epoch 3/16
200/200 [==============================] - 0s 226us/sample - loss: 0.2082 - accuracy: 0.9650 - val_loss: 0.2150 - val_accuracy: 0.9503
Epoch 4/16
200/200 [==============================] - 0s 212us/sample - loss: 0.1695 - accuracy: 0.9800 - val_loss: 0.1840 - val_accuracy: 0.9625
Epoch 5/16
200/200 [==============================] - 0s 226us/sample - loss: 0.1428 - accuracy: 0.9800 - val_loss: 0.1602 - val_accuracy: 0.9706
Epoch 6/16
200/200 [==============================] - 0s 236us/sample - loss: 0.1221 - accuracy: 0.9850 - val_loss: 0.1424 - val_accuracy: 0.9797
Epoch 7/16
200/200 [==============================] - 0s 218us/sample - loss: 0.1067 - accuracy: 0.9950 - val_loss: 0.1293 - val_accuracy: 0.9828
Epoch 8/16
200/200 [==============================] - 0s 229us/sample - loss: 0.0952 - accuracy: 0.9950 - val_loss: 0.1186 - val_accuracy: 0.9848
Epoch 9/16
200/200 [==============================] - 0s 224us/sample - loss: 0.0858 - accuracy: 0.9950 - val_loss: 0.1099 - val_accuracy: 0.9848
Epoch 10/16
200/200 [==============================] - 0s 241us/sample - loss: 0.0781 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9878
Epoch 11/16
200/200 [==============================] - 0s 234us/sample - loss: 0.0719 - accuracy: 1.0000 - val_loss: 0.0964 - val_accuracy: 0.9888
Epoch 12/16
200/200 [==============================] - 0s 222us/sample - loss: 0.0664 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9888
Epoch 13/16
200/200 [==============================] - 0s 228us/sample - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9899
Epoch 14/16
200/200 [==============================] - 0s 225us/sample - loss: 0.0575 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 0.9899
Epoch 15/16
200/200 [==============================] - 0s 219us/sample - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9899
Epoch 16/16
200/200 [==============================] - 0s 221us/sample - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9899
</pre></div>
</div>
</div>
</div>
<p>So, what’s the final verdict?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_B</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_B</span><span class="p">,</span> <span class="n">y_test_B</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>2000/2000 [==============================] - 0s 28us/sample - loss: 0.1426 - accuracy: 0.9695
</pre></div>
</div>
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>[0.14263125681877137, 0.9695]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_B_on_A</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_B</span><span class="p">,</span> <span class="n">y_test_B</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>2000/2000 [==============================] - 0s 25us/sample - loss: 0.0697 - accuracy: 0.9925
</pre></div>
</div>
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>[0.06966363421082497, 0.9925]
</pre></div>
</div>
</div>
</div>
<p>Great! We got quite a bit of transfer: the error rate dropped by a factor of 4!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="mi">100</span> <span class="o">-</span> <span class="mf">96.95</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">100</span> <span class="o">-</span> <span class="mf">99.25</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>3.933333333333337
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="faster-optimizers">
<h1>Faster Optimizers<a class="headerlink" href="#faster-optimizers" title="Permalink to this headline">¶</a></h1>
<div class="section" id="momentum-optimization">
<h2>Momentum optimization<a class="headerlink" href="#momentum-optimization" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="nesterov-accelerated-gradient">
<h2>Nesterov Accelerated Gradient<a class="headerlink" href="#nesterov-accelerated-gradient" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">nesterov</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="adagrad">
<h2>AdaGrad<a class="headerlink" href="#adagrad" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="rmsprop">
<h2>RMSProp<a class="headerlink" href="#rmsprop" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">rho</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="adam-optimization">
<h2>Adam Optimization<a class="headerlink" href="#adam-optimization" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="adamax-optimization">
<h2>Adamax Optimization<a class="headerlink" href="#adamax-optimization" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adamax</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="nadam-optimization">
<h2>Nadam Optimization<a class="headerlink" href="#nadam-optimization" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Nadam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="learning-rate-scheduling">
<h2>Learning Rate Scheduling<a class="headerlink" href="#learning-rate-scheduling" title="Permalink to this headline">¶</a></h2>
<div class="section" id="power-scheduling">
<h3>Power Scheduling<a class="headerlink" href="#power-scheduling" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">lr</span> <span class="pre">=</span> <span class="pre">lr0</span> <span class="pre">/</span> <span class="pre">(1</span> <span class="pre">+</span> <span class="pre">steps</span> <span class="pre">/</span> <span class="pre">s)**c</span></code></p>
<ul class="simple">
<li><p>Keras uses <code class="docutils literal notranslate"><span class="pre">c=1</span></code> and <code class="docutils literal notranslate"><span class="pre">s</span> <span class="pre">=</span> <span class="pre">1</span> <span class="pre">/</span> <span class="pre">decay</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">decay</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">25</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples, validate on 5000 samples
Epoch 1/25
55000/55000 [==============================] - 2s 45us/sample - loss: 0.4842 - accuracy: 0.8319 - val_loss: 0.4167 - val_accuracy: 0.8572
Epoch 2/25
55000/55000 [==============================] - 2s 41us/sample - loss: 0.3789 - accuracy: 0.8646 - val_loss: 0.3781 - val_accuracy: 0.8678
Epoch 3/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.3461 - accuracy: 0.8768 - val_loss: 0.3690 - val_accuracy: 0.8706
Epoch 4/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.3252 - accuracy: 0.8836 - val_loss: 0.3532 - val_accuracy: 0.8770
Epoch 5/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.3091 - accuracy: 0.8896 - val_loss: 0.3454 - val_accuracy: 0.8814
Epoch 6/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2970 - accuracy: 0.8938 - val_loss: 0.3431 - val_accuracy: 0.8798
Epoch 7/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2862 - accuracy: 0.8975 - val_loss: 0.3377 - val_accuracy: 0.8850
Epoch 8/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2774 - accuracy: 0.9010 - val_loss: 0.3324 - val_accuracy: 0.8850
Epoch 9/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2696 - accuracy: 0.9036 - val_loss: 0.3297 - val_accuracy: 0.8884
Epoch 10/25
55000/55000 [==============================] - 2s 39us/sample - loss: 0.2625 - accuracy: 0.9054 - val_loss: 0.3309 - val_accuracy: 0.8852
Epoch 11/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2564 - accuracy: 0.9083 - val_loss: 0.3255 - val_accuracy: 0.8894
Epoch 12/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2508 - accuracy: 0.9101 - val_loss: 0.3242 - val_accuracy: 0.8900
Epoch 13/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2458 - accuracy: 0.9119 - val_loss: 0.3239 - val_accuracy: 0.8894
Epoch 14/25
55000/55000 [==============================] - 2s 39us/sample - loss: 0.2413 - accuracy: 0.9145 - val_loss: 0.3248 - val_accuracy: 0.8902
Epoch 15/25
55000/55000 [==============================] - 2s 39us/sample - loss: 0.2371 - accuracy: 0.9161 - val_loss: 0.3201 - val_accuracy: 0.8900
Epoch 16/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2328 - accuracy: 0.9171 - val_loss: 0.3223 - val_accuracy: 0.8894
Epoch 17/25
55000/55000 [==============================] - 2s 41us/sample - loss: 0.2295 - accuracy: 0.9187 - val_loss: 0.3181 - val_accuracy: 0.8908
Epoch 18/25
55000/55000 [==============================] - 2s 39us/sample - loss: 0.2254 - accuracy: 0.9190 - val_loss: 0.3220 - val_accuracy: 0.8890
Epoch 19/25
55000/55000 [==============================] - 2s 41us/sample - loss: 0.2224 - accuracy: 0.9216 - val_loss: 0.3205 - val_accuracy: 0.8884
Epoch 20/25
55000/55000 [==============================] - 2s 42us/sample - loss: 0.2194 - accuracy: 0.9234 - val_loss: 0.3178 - val_accuracy: 0.8920
Epoch 21/25
55000/55000 [==============================] - 2s 42us/sample - loss: 0.2166 - accuracy: 0.9237 - val_loss: 0.3174 - val_accuracy: 0.8918
Epoch 22/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2135 - accuracy: 0.9252 - val_loss: 0.3185 - val_accuracy: 0.8888
Epoch 23/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2110 - accuracy: 0.9253 - val_loss: 0.3174 - val_accuracy: 0.8924
Epoch 24/25
55000/55000 [==============================] - 2s 38us/sample - loss: 0.2084 - accuracy: 0.9270 - val_loss: 0.3193 - val_accuracy: 0.8894
Epoch 25/25
55000/55000 [==============================] - 2s 41us/sample - loss: 0.2063 - accuracy: 0.9274 - val_loss: 0.3179 - val_accuracy: 0.8934
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">decay</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">n_steps_per_epoch</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span>
<span class="n">lrs</span> <span class="o">=</span> <span class="n">learning_rate</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">decay</span> <span class="o">*</span> <span class="n">epochs</span> <span class="o">*</span> <span class="n">n_steps_per_epoch</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">lrs</span><span class="p">,</span>  <span class="s2">&quot;o-&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Learning Rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Power Scheduling&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/11_training_deep_neural_networks_117_0.png" src="../../_images/11_training_deep_neural_networks_117_0.png" />
</div>
</div>
</div>
<div class="section" id="exponential-scheduling">
<h3>Exponential Scheduling<a class="headerlink" href="#exponential-scheduling" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">lr</span> <span class="pre">=</span> <span class="pre">lr0</span> <span class="pre">*</span> <span class="pre">0.1**(epoch</span> <span class="pre">/</span> <span class="pre">s)</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">exponential_decay_fn</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">0.01</span> <span class="o">*</span> <span class="mf">0.1</span><span class="o">**</span><span class="p">(</span><span class="n">epoch</span> <span class="o">/</span> <span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">exponential_decay</span><span class="p">(</span><span class="n">lr0</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">exponential_decay_fn</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">lr0</span> <span class="o">*</span> <span class="mf">0.1</span><span class="o">**</span><span class="p">(</span><span class="n">epoch</span> <span class="o">/</span> <span class="n">s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">exponential_decay_fn</span>

<span class="n">exponential_decay_fn</span> <span class="o">=</span> <span class="n">exponential_decay</span><span class="p">(</span><span class="n">lr0</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;nadam&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">25</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">exponential_decay_fn</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span>
                    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">lr_scheduler</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples, validate on 5000 samples
Epoch 1/25
55000/55000 [==============================] - 5s 99us/sample - loss: 0.8503 - accuracy: 0.7562 - val_loss: 0.7115 - val_accuracy: 0.7578
Epoch 2/25
55000/55000 [==============================] - 5s 95us/sample - loss: 0.7107 - accuracy: 0.7861 - val_loss: 0.7508 - val_accuracy: 0.7642
Epoch 3/25
55000/55000 [==============================] - 5s 88us/sample - loss: 0.6246 - accuracy: 0.8084 - val_loss: 0.6204 - val_accuracy: 0.7968
Epoch 4/25
55000/55000 [==============================] - 5s 91us/sample - loss: 0.5598 - accuracy: 0.8278 - val_loss: 0.6224 - val_accuracy: 0.8446
Epoch 5/25
55000/55000 [==============================] - 5s 87us/sample - loss: 0.5242 - accuracy: 0.8365 - val_loss: 0.5441 - val_accuracy: 0.8338
Epoch 6/25
55000/55000 [==============================] - 5s 84us/sample - loss: 0.4533 - accuracy: 0.8541 - val_loss: 0.5239 - val_accuracy: 0.8466
Epoch 7/25
55000/55000 [==============================] - 5s 83us/sample - loss: 0.4378 - accuracy: 0.8613 - val_loss: 0.5651 - val_accuracy: 0.8346
Epoch 8/25
55000/55000 [==============================] - 5s 83us/sample - loss: 0.3915 - accuracy: 0.8705 - val_loss: 0.5245 - val_accuracy: 0.8422
Epoch 9/25
55000/55000 [==============================] - 5s 85us/sample - loss: 0.3693 - accuracy: 0.8772 - val_loss: 0.4801 - val_accuracy: 0.8674
Epoch 10/25
55000/55000 [==============================] - 5s 89us/sample - loss: 0.3403 - accuracy: 0.8855 - val_loss: 0.4553 - val_accuracy: 0.8672
Epoch 11/25
55000/55000 [==============================] - 5s 92us/sample - loss: 0.3194 - accuracy: 0.8933 - val_loss: 0.4427 - val_accuracy: 0.8794
Epoch 12/25
55000/55000 [==============================] - 4s 82us/sample - loss: 0.2960 - accuracy: 0.8991 - val_loss: 0.4337 - val_accuracy: 0.8674
Epoch 13/25
55000/55000 [==============================] - 4s 77us/sample - loss: 0.2744 - accuracy: 0.9069 - val_loss: 0.4876 - val_accuracy: 0.8762
Epoch 14/25
55000/55000 [==============================] - 4s 73us/sample - loss: 0.2600 - accuracy: 0.9104 - val_loss: 0.4965 - val_accuracy: 0.8852
Epoch 15/25
55000/55000 [==============================] - 4s 73us/sample - loss: 0.2398 - accuracy: 0.9175 - val_loss: 0.5139 - val_accuracy: 0.8812
Epoch 16/25
55000/55000 [==============================] - 4s 75us/sample - loss: 0.2229 - accuracy: 0.9237 - val_loss: 0.5102 - val_accuracy: 0.8812
Epoch 17/25
55000/55000 [==============================] - 4s 74us/sample - loss: 0.2100 - accuracy: 0.9281 - val_loss: 0.4916 - val_accuracy: 0.8824
Epoch 18/25
55000/55000 [==============================] - 4s 75us/sample - loss: 0.1989 - accuracy: 0.9321 - val_loss: 0.5105 - val_accuracy: 0.8826
Epoch 19/25
55000/55000 [==============================] - 5s 90us/sample - loss: 0.1861 - accuracy: 0.9362 - val_loss: 0.5424 - val_accuracy: 0.8794
Epoch 20/25
55000/55000 [==============================] - 5s 83us/sample - loss: 0.1717 - accuracy: 0.9410 - val_loss: 0.5630 - val_accuracy: 0.8854
Epoch 21/25
55000/55000 [==============================] - 5s 86us/sample - loss: 0.1638 - accuracy: 0.9450 - val_loss: 0.5584 - val_accuracy: 0.8824
Epoch 22/25
55000/55000 [==============================] - 4s 80us/sample - loss: 0.1545 - accuracy: 0.9487 - val_loss: 0.5977 - val_accuracy: 0.8860
Epoch 23/25
55000/55000 [==============================] - 5s 87us/sample - loss: 0.1426 - accuracy: 0.9520 - val_loss: 0.6271 - val_accuracy: 0.8836
Epoch 24/25
55000/55000 [==============================] - 5s 90us/sample - loss: 0.1364 - accuracy: 0.9546 - val_loss: 0.6106 - val_accuracy: 0.8826
Epoch 25/25
55000/55000 [==============================] - 5s 91us/sample - loss: 0.1323 - accuracy: 0.9567 - val_loss: 0.6387 - val_accuracy: 0.8850
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">],</span> <span class="s2">&quot;o-&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.011</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Learning Rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Exponential Scheduling&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/11_training_deep_neural_networks_124_0.png" src="../../_images/11_training_deep_neural_networks_124_0.png" />
</div>
</div>
<p>The schedule function can take the current learning rate as a second argument:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">exponential_decay_fn</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">lr</span> <span class="o">*</span> <span class="mf">0.1</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>If you want to update the learning rate at each iteration rather than at each epoch, you must write your own callback class:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">K</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">backend</span>

<span class="k">class</span> <span class="nc">ExponentialDecay</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">40000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s</span> <span class="o">=</span> <span class="n">s</span>

    <span class="k">def</span> <span class="nf">on_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Note: the `batch` argument is reset at each epoch</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>
        <span class="n">K</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">lr</span> <span class="o">*</span> <span class="mf">0.1</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">s</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
        <span class="n">logs</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">lr0</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Nadam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="n">lr0</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">25</span>

<span class="n">s</span> <span class="o">=</span> <span class="mi">20</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span> <span class="o">//</span> <span class="mi">32</span> <span class="c1"># number of steps in 20 epochs (batch size = 32)</span>
<span class="n">exp_decay</span> <span class="o">=</span> <span class="n">ExponentialDecay</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span>
                    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">exp_decay</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples, validate on 5000 samples
Epoch 1/25
55000/55000 [==============================] - 6s 106us/sample - loss: 0.7950 - accuracy: 0.7678 - val_loss: 0.7626 - val_accuracy: 0.7202
Epoch 2/25
55000/55000 [==============================] - 6s 103us/sample - loss: 0.6238 - accuracy: 0.8097 - val_loss: 0.5616 - val_accuracy: 0.8304
Epoch 3/25
55000/55000 [==============================] - 6s 108us/sample - loss: 0.5716 - accuracy: 0.8217 - val_loss: 0.6381 - val_accuracy: 0.8120
Epoch 4/25
55000/55000 [==============================] - 6s 106us/sample - loss: 0.5121 - accuracy: 0.8391 - val_loss: 0.6855 - val_accuracy: 0.8114
Epoch 5/25
55000/55000 [==============================] - 6s 103us/sample - loss: 0.4785 - accuracy: 0.8495 - val_loss: 0.5208 - val_accuracy: 0.8556
Epoch 6/25
55000/55000 [==============================] - 6s 101us/sample - loss: 0.4188 - accuracy: 0.8659 - val_loss: 0.5239 - val_accuracy: 0.8542
Epoch 7/25
55000/55000 [==============================] - 6s 111us/sample - loss: 0.3950 - accuracy: 0.8711 - val_loss: 0.4905 - val_accuracy: 0.8576
Epoch 8/25
55000/55000 [==============================] - 5s 99us/sample - loss: 0.3658 - accuracy: 0.8799 - val_loss: 0.4733 - val_accuracy: 0.8646
Epoch 9/25
55000/55000 [==============================] - 6s 109us/sample - loss: 0.3451 - accuracy: 0.8855 - val_loss: 0.4483 - val_accuracy: 0.8688
Epoch 10/25
55000/55000 [==============================] - 6s 110us/sample - loss: 0.3192 - accuracy: 0.8933 - val_loss: 0.4850 - val_accuracy: 0.8810
Epoch 11/25
55000/55000 [==============================] - 6s 113us/sample - loss: 0.3002 - accuracy: 0.8986 - val_loss: 0.4633 - val_accuracy: 0.8776
Epoch 12/25
55000/55000 [==============================] - 6s 115us/sample - loss: 0.2756 - accuracy: 0.9051 - val_loss: 0.4408 - val_accuracy: 0.8822
Epoch 13/25
55000/55000 [==============================] - 6s 113us/sample - loss: 0.2590 - accuracy: 0.9116 - val_loss: 0.4711 - val_accuracy: 0.8836
Epoch 14/25
55000/55000 [==============================] - 6s 117us/sample - loss: 0.2500 - accuracy: 0.9178 - val_loss: 0.4527 - val_accuracy: 0.8886
Epoch 15/25
55000/55000 [==============================] - 7s 122us/sample - loss: 0.2213 - accuracy: 0.9236 - val_loss: 0.4510 - val_accuracy: 0.8814
Epoch 16/25
55000/55000 [==============================] - 6s 111us/sample - loss: 0.2052 - accuracy: 0.9289 - val_loss: 0.4838 - val_accuracy: 0.8856
Epoch 17/25
55000/55000 [==============================] - 6s 104us/sample - loss: 0.1892 - accuracy: 0.9343 - val_loss: 0.4641 - val_accuracy: 0.8874
Epoch 18/25
55000/55000 [==============================] - 6s 109us/sample - loss: 0.1797 - accuracy: 0.9382 - val_loss: 0.4913 - val_accuracy: 0.8932
Epoch 19/25
55000/55000 [==============================] - 6s 111us/sample - loss: 0.1676 - accuracy: 0.9418 - val_loss: 0.4841 - val_accuracy: 0.8882
Epoch 20/25
55000/55000 [==============================] - 6s 110us/sample - loss: 0.1548 - accuracy: 0.9471 - val_loss: 0.5274 - val_accuracy: 0.8916
Epoch 21/25
55000/55000 [==============================] - 6s 116us/sample - loss: 0.1460 - accuracy: 0.9501 - val_loss: 0.5155 - val_accuracy: 0.8922
Epoch 22/25
55000/55000 [==============================] - 7s 118us/sample - loss: 0.1356 - accuracy: 0.9533 - val_loss: 0.5479 - val_accuracy: 0.8912
Epoch 23/25
55000/55000 [==============================] - 7s 119us/sample - loss: 0.1270 - accuracy: 0.9570 - val_loss: 0.5588 - val_accuracy: 0.8912
Epoch 24/25
55000/55000 [==============================] - 6s 108us/sample - loss: 0.1202 - accuracy: 0.9597 - val_loss: 0.6076 - val_accuracy: 0.8948
Epoch 25/25
55000/55000 [==============================] - 6s 107us/sample - loss: 0.1145 - accuracy: 0.9620 - val_loss: 0.6109 - val_accuracy: 0.8952
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_steps</span> <span class="o">=</span> <span class="n">n_epochs</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span> <span class="o">//</span> <span class="mi">32</span>
<span class="n">steps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_steps</span><span class="p">)</span>
<span class="n">lrs</span> <span class="o">=</span> <span class="n">lr0</span> <span class="o">*</span> <span class="mf">0.1</span><span class="o">**</span><span class="p">(</span><span class="n">steps</span> <span class="o">/</span> <span class="n">s</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">lrs</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">lr0</span> <span class="o">*</span> <span class="mf">1.1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Batch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Learning Rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Exponential Scheduling (per batch)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/11_training_deep_neural_networks_130_0.png" src="../../_images/11_training_deep_neural_networks_130_0.png" />
</div>
</div>
</div>
<div class="section" id="piecewise-constant-scheduling">
<h3>Piecewise Constant Scheduling<a class="headerlink" href="#piecewise-constant-scheduling" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">piecewise_constant_fn</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.01</span>
    <span class="k">elif</span> <span class="n">epoch</span> <span class="o">&lt;</span> <span class="mi">15</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.005</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.001</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">piecewise_constant</span><span class="p">(</span><span class="n">boundaries</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
    <span class="n">boundaries</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">boundaries</span><span class="p">)</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">piecewise_constant_fn</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">values</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">boundaries</span> <span class="o">&gt;</span> <span class="n">epoch</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">piecewise_constant_fn</span>

<span class="n">piecewise_constant_fn</span> <span class="o">=</span> <span class="n">piecewise_constant</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.005</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span><span class="n">piecewise_constant_fn</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;nadam&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">25</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span>
                    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">lr_scheduler</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples, validate on 5000 samples
Epoch 1/25
55000/55000 [==============================] - 6s 105us/sample - loss: 0.8429 - accuracy: 0.7634 - val_loss: 0.9667 - val_accuracy: 0.6432
Epoch 2/25
55000/55000 [==============================] - 5s 97us/sample - loss: 0.8500 - accuracy: 0.7677 - val_loss: 0.6907 - val_accuracy: 0.8070
Epoch 3/25
55000/55000 [==============================] - 5s 97us/sample - loss: 0.7974 - accuracy: 0.7831 - val_loss: 0.8228 - val_accuracy: 0.7608
Epoch 4/25
55000/55000 [==============================] - 5s 98us/sample - loss: 0.8931 - accuracy: 0.7344 - val_loss: 1.1275 - val_accuracy: 0.7434
Epoch 5/25
55000/55000 [==============================] - 6s 102us/sample - loss: 0.9565 - accuracy: 0.7025 - val_loss: 0.8436 - val_accuracy: 0.7664
Epoch 6/25
55000/55000 [==============================] - 6s 104us/sample - loss: 0.6047 - accuracy: 0.7910 - val_loss: 0.7323 - val_accuracy: 0.8054
Epoch 7/25
55000/55000 [==============================] - 5s 99us/sample - loss: 0.5715 - accuracy: 0.8027 - val_loss: 0.6902 - val_accuracy: 0.7888
Epoch 8/25
55000/55000 [==============================] - 6s 102us/sample - loss: 0.5593 - accuracy: 0.8068 - val_loss: 0.6892 - val_accuracy: 0.7762
Epoch 9/25
55000/55000 [==============================] - 6s 101us/sample - loss: 0.5603 - accuracy: 0.8135 - val_loss: 0.6659 - val_accuracy: 0.7780
Epoch 10/25
55000/55000 [==============================] - 6s 102us/sample - loss: 0.5320 - accuracy: 0.8303 - val_loss: 0.6034 - val_accuracy: 0.8246
Epoch 11/25
55000/55000 [==============================] - 6s 105us/sample - loss: 0.4994 - accuracy: 0.8472 - val_loss: 0.5903 - val_accuracy: 0.8458
Epoch 12/25
55000/55000 [==============================] - 6s 104us/sample - loss: 0.5150 - accuracy: 0.8429 - val_loss: 0.6375 - val_accuracy: 0.8274
Epoch 13/25
55000/55000 [==============================] - 6s 103us/sample - loss: 0.4800 - accuracy: 0.8591 - val_loss: 0.6542 - val_accuracy: 0.8454
Epoch 14/25
55000/55000 [==============================] - 6s 105us/sample - loss: 0.4637 - accuracy: 0.8595 - val_loss: 0.6974 - val_accuracy: 0.8538
Epoch 15/25
55000/55000 [==============================] - 6s 102us/sample - loss: 0.5155 - accuracy: 0.8531 - val_loss: 0.6640 - val_accuracy: 0.8426
Epoch 16/25
55000/55000 [==============================] - 6s 105us/sample - loss: 0.3436 - accuracy: 0.8896 - val_loss: 0.5793 - val_accuracy: 0.8584
Epoch 17/25
55000/55000 [==============================] - 6s 102us/sample - loss: 0.3130 - accuracy: 0.8979 - val_loss: 0.5593 - val_accuracy: 0.8624
Epoch 18/25
55000/55000 [==============================] - 6s 110us/sample - loss: 0.2968 - accuracy: 0.9020 - val_loss: 0.5435 - val_accuracy: 0.8666
Epoch 19/25
55000/55000 [==============================] - 6s 109us/sample - loss: 0.2859 - accuracy: 0.9075 - val_loss: 0.5807 - val_accuracy: 0.8648
Epoch 20/25
55000/55000 [==============================] - 6s 109us/sample - loss: 0.2758 - accuracy: 0.9109 - val_loss: 0.5802 - val_accuracy: 0.8698
Epoch 21/25
55000/55000 [==============================] - 6s 108us/sample - loss: 0.2670 - accuracy: 0.9143 - val_loss: 0.5445 - val_accuracy: 0.8688
Epoch 22/25
55000/55000 [==============================] - 6s 105us/sample - loss: 0.2580 - accuracy: 0.9173 - val_loss: 0.5952 - val_accuracy: 0.8708
Epoch 23/25
55000/55000 [==============================] - 6s 105us/sample - loss: 0.2524 - accuracy: 0.9193 - val_loss: 0.5608 - val_accuracy: 0.8700
Epoch 24/25
55000/55000 [==============================] - 6s 106us/sample - loss: 0.2449 - accuracy: 0.9216 - val_loss: 0.5656 - val_accuracy: 0.8746
Epoch 25/25
55000/55000 [==============================] - 6s 109us/sample - loss: 0.2409 - accuracy: 0.9228 - val_loss: 0.6174 - val_accuracy: 0.8714
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="p">[</span><span class="n">piecewise_constant_fn</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span> <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">history</span><span class="o">.</span><span class="n">epoch</span><span class="p">],</span> <span class="s2">&quot;o-&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.011</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Learning Rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Piecewise Constant Scheduling&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/11_training_deep_neural_networks_135_0.png" src="../../_images/11_training_deep_neural_networks_135_0.png" />
</div>
</div>
</div>
<div class="section" id="performance-scheduling">
<h3>Performance Scheduling<a class="headerlink" href="#performance-scheduling" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">25</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span>
                    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">lr_scheduler</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples, validate on 5000 samples
Epoch 1/25
55000/55000 [==============================] - 2s 44us/sample - loss: 0.5950 - accuracy: 0.8063 - val_loss: 0.5177 - val_accuracy: 0.8426
Epoch 2/25
55000/55000 [==============================] - 2s 39us/sample - loss: 0.5091 - accuracy: 0.8373 - val_loss: 0.4850 - val_accuracy: 0.8534
Epoch 3/25
55000/55000 [==============================] - 2s 41us/sample - loss: 0.5029 - accuracy: 0.8437 - val_loss: 0.4905 - val_accuracy: 0.8400
Epoch 4/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.5372 - accuracy: 0.8436 - val_loss: 0.6500 - val_accuracy: 0.8378
Epoch 5/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.5189 - accuracy: 0.8497 - val_loss: 0.4873 - val_accuracy: 0.8618
Epoch 6/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.5190 - accuracy: 0.8515 - val_loss: 0.8216 - val_accuracy: 0.8420
Epoch 7/25
55000/55000 [==============================] - 2s 41us/sample - loss: 0.5411 - accuracy: 0.8513 - val_loss: 0.7188 - val_accuracy: 0.8286
Epoch 8/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.3137 - accuracy: 0.8926 - val_loss: 0.4186 - val_accuracy: 0.8738
Epoch 9/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2553 - accuracy: 0.9067 - val_loss: 0.3912 - val_accuracy: 0.8888
Epoch 10/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2292 - accuracy: 0.9150 - val_loss: 0.3965 - val_accuracy: 0.8840
Epoch 11/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2207 - accuracy: 0.9185 - val_loss: 0.4154 - val_accuracy: 0.8744
Epoch 12/25
55000/55000 [==============================] - 2s 41us/sample - loss: 0.2049 - accuracy: 0.9242 - val_loss: 0.4514 - val_accuracy: 0.8810
Epoch 13/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.1987 - accuracy: 0.9266 - val_loss: 0.4412 - val_accuracy: 0.8794
Epoch 14/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.1880 - accuracy: 0.9310 - val_loss: 0.4852 - val_accuracy: 0.8892
Epoch 15/25
55000/55000 [==============================] - 2s 41us/sample - loss: 0.1321 - accuracy: 0.9477 - val_loss: 0.4251 - val_accuracy: 0.8934
Epoch 16/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.1148 - accuracy: 0.9540 - val_loss: 0.4347 - val_accuracy: 0.8890
Epoch 17/25
55000/55000 [==============================] - 2s 41us/sample - loss: 0.1063 - accuracy: 0.9576 - val_loss: 0.4490 - val_accuracy: 0.8906
Epoch 18/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.1003 - accuracy: 0.9603 - val_loss: 0.4748 - val_accuracy: 0.8940
Epoch 19/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.0948 - accuracy: 0.9626 - val_loss: 0.4804 - val_accuracy: 0.8926
Epoch 20/25
55000/55000 [==============================] - 2s 43us/sample - loss: 0.0730 - accuracy: 0.9719 - val_loss: 0.4814 - val_accuracy: 0.8912
Epoch 21/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.0673 - accuracy: 0.9741 - val_loss: 0.5017 - val_accuracy: 0.8900
Epoch 22/25
55000/55000 [==============================] - 2s 41us/sample - loss: 0.0633 - accuracy: 0.9759 - val_loss: 0.5200 - val_accuracy: 0.8930
Epoch 23/25
55000/55000 [==============================] - 2s 41us/sample - loss: 0.0603 - accuracy: 0.9781 - val_loss: 0.5209 - val_accuracy: 0.8914
Epoch 24/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.0573 - accuracy: 0.9785 - val_loss: 0.5416 - val_accuracy: 0.8934
Epoch 25/25
55000/55000 [==============================] - 2s 41us/sample - loss: 0.0488 - accuracy: 0.9830 - val_loss: 0.5411 - val_accuracy: 0.8940
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">],</span> <span class="s2">&quot;bo-&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Learning Rate&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_epochs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="n">ax2</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">twinx</span><span class="p">()</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">],</span> <span class="s2">&quot;r^-&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Validation Loss&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Reduce LR on Plateau&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/11_training_deep_neural_networks_139_0.png" src="../../_images/11_training_deep_neural_networks_139_0.png" />
</div>
</div>
</div>
<div class="section" id="tf-keras-schedulers">
<h3>tf.keras schedulers<a class="headerlink" href="#tf-keras-schedulers" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">s</span> <span class="o">=</span> <span class="mi">20</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span> <span class="o">//</span> <span class="mi">32</span> <span class="c1"># number of steps in 20 epochs (batch size = 32)</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">schedules</span><span class="o">.</span><span class="n">ExponentialDecay</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">25</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples, validate on 5000 samples
Epoch 1/25
55000/55000 [==============================] - 2s 44us/sample - loss: 0.4872 - accuracy: 0.8296 - val_loss: 0.4141 - val_accuracy: 0.8548
Epoch 2/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.3829 - accuracy: 0.8643 - val_loss: 0.3773 - val_accuracy: 0.8704
Epoch 3/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.3495 - accuracy: 0.8763 - val_loss: 0.3696 - val_accuracy: 0.8730
Epoch 4/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.3274 - accuracy: 0.8831 - val_loss: 0.3545 - val_accuracy: 0.8760
Epoch 5/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.3102 - accuracy: 0.8899 - val_loss: 0.3460 - val_accuracy: 0.8784
Epoch 6/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2971 - accuracy: 0.8945 - val_loss: 0.3415 - val_accuracy: 0.8796
Epoch 7/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2858 - accuracy: 0.8985 - val_loss: 0.3353 - val_accuracy: 0.8834
Epoch 8/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2767 - accuracy: 0.9018 - val_loss: 0.3321 - val_accuracy: 0.8854
Epoch 9/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2685 - accuracy: 0.9043 - val_loss: 0.3281 - val_accuracy: 0.8862
Epoch 10/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2612 - accuracy: 0.9075 - val_loss: 0.3304 - val_accuracy: 0.8832
Epoch 11/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2554 - accuracy: 0.9097 - val_loss: 0.3261 - val_accuracy: 0.8868
Epoch 12/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2502 - accuracy: 0.9115 - val_loss: 0.3246 - val_accuracy: 0.8876
Epoch 13/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2456 - accuracy: 0.9133 - val_loss: 0.3243 - val_accuracy: 0.8870
Epoch 14/25
55000/55000 [==============================] - 2s 41us/sample - loss: 0.2416 - accuracy: 0.9141 - val_loss: 0.3238 - val_accuracy: 0.8862
Epoch 15/25
55000/55000 [==============================] - 2s 41us/sample - loss: 0.2380 - accuracy: 0.9170 - val_loss: 0.3197 - val_accuracy: 0.8876
Epoch 16/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2346 - accuracy: 0.9169 - val_loss: 0.3207 - val_accuracy: 0.8866
Epoch 17/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2321 - accuracy: 0.9186 - val_loss: 0.3182 - val_accuracy: 0.8878
Epoch 18/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2291 - accuracy: 0.9191 - val_loss: 0.3206 - val_accuracy: 0.8884
Epoch 19/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2271 - accuracy: 0.9201 - val_loss: 0.3194 - val_accuracy: 0.8876
Epoch 20/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2252 - accuracy: 0.9215 - val_loss: 0.3178 - val_accuracy: 0.8880
Epoch 21/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2234 - accuracy: 0.9218 - val_loss: 0.3171 - val_accuracy: 0.8904
Epoch 22/25
55000/55000 [==============================] - 2s 41us/sample - loss: 0.2218 - accuracy: 0.9230 - val_loss: 0.3171 - val_accuracy: 0.8884
Epoch 23/25
55000/55000 [==============================] - 2s 40us/sample - loss: 0.2204 - accuracy: 0.9227 - val_loss: 0.3168 - val_accuracy: 0.8882
Epoch 24/25
55000/55000 [==============================] - 2s 39us/sample - loss: 0.2191 - accuracy: 0.9240 - val_loss: 0.3173 - val_accuracy: 0.8900
Epoch 25/25
55000/55000 [==============================] - 2s 39us/sample - loss: 0.2182 - accuracy: 0.9239 - val_loss: 0.3166 - val_accuracy: 0.8892
</pre></div>
</div>
</div>
</div>
<p>For piecewise constant scheduling, try this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">schedules</span><span class="o">.</span><span class="n">PiecewiseConstantDecay</span><span class="p">(</span>
    <span class="n">boundaries</span><span class="o">=</span><span class="p">[</span><span class="mf">5.</span> <span class="o">*</span> <span class="n">n_steps_per_epoch</span><span class="p">,</span> <span class="mf">15.</span> <span class="o">*</span> <span class="n">n_steps_per_epoch</span><span class="p">],</span>
    <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.005</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="cycle-scheduling">
<h3>1Cycle scheduling<a class="headerlink" href="#cycle-scheduling" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">K</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">backend</span>

<span class="k">class</span> <span class="nc">ExponentialLearningRate</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">factor</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">factor</span> <span class="o">=</span> <span class="n">factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rates</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">logs</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">])</span>
        <span class="n">K</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">factor</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">find_learning_rate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">min_rate</span><span class="o">=</span><span class="mi">10</span><span class="o">**-</span><span class="mi">5</span><span class="p">,</span> <span class="n">max_rate</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">init_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
    <span class="n">iterations</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">epochs</span>
    <span class="n">factor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">max_rate</span> <span class="o">/</span> <span class="n">min_rate</span><span class="p">)</span> <span class="o">/</span> <span class="n">iterations</span><span class="p">)</span>
    <span class="n">init_lr</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">K</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">min_rate</span><span class="p">)</span>
    <span class="n">exp_lr</span> <span class="o">=</span> <span class="n">ExponentialLearningRate</span><span class="p">(</span><span class="n">factor</span><span class="p">)</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                        <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">exp_lr</span><span class="p">])</span>
    <span class="n">K</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">init_lr</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">exp_lr</span><span class="o">.</span><span class="n">rates</span><span class="p">,</span> <span class="n">exp_lr</span><span class="o">.</span><span class="n">losses</span>

<span class="k">def</span> <span class="nf">plot_lr_vs_loss</span><span class="p">(</span><span class="n">rates</span><span class="p">,</span> <span class="n">losses</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">rates</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">losses</span><span class="p">),</span> <span class="nb">min</span><span class="p">(</span><span class="n">rates</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">rates</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="nb">min</span><span class="p">(</span><span class="n">rates</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">rates</span><span class="p">),</span> <span class="nb">min</span><span class="p">(</span><span class="n">losses</span><span class="p">),</span> <span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="nb">min</span><span class="p">(</span><span class="n">losses</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Learning rate&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">rates</span><span class="p">,</span> <span class="n">losses</span> <span class="o">=</span> <span class="n">find_learning_rate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">plot_lr_vs_loss</span><span class="p">(</span><span class="n">rates</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples
55000/55000 [==============================] - 1s 22us/sample - loss: nan - accuracy: 0.3879
</pre></div>
</div>
<img alt="../../_images/11_training_deep_neural_networks_147_1.png" src="../../_images/11_training_deep_neural_networks_147_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">OneCycleScheduler</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iterations</span><span class="p">,</span> <span class="n">max_rate</span><span class="p">,</span> <span class="n">start_rate</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">last_iterations</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">last_rate</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iterations</span> <span class="o">=</span> <span class="n">iterations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_rate</span> <span class="o">=</span> <span class="n">max_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_rate</span> <span class="o">=</span> <span class="n">start_rate</span> <span class="ow">or</span> <span class="n">max_rate</span> <span class="o">/</span> <span class="mi">10</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_iterations</span> <span class="o">=</span> <span class="n">last_iterations</span> <span class="ow">or</span> <span class="n">iterations</span> <span class="o">//</span> <span class="mi">10</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">half_iteration</span> <span class="o">=</span> <span class="p">(</span><span class="n">iterations</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_iterations</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_rate</span> <span class="o">=</span> <span class="n">last_rate</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_rate</span> <span class="o">/</span> <span class="mi">1000</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">def</span> <span class="nf">_interpolate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iter1</span><span class="p">,</span> <span class="n">iter2</span><span class="p">,</span> <span class="n">rate1</span><span class="p">,</span> <span class="n">rate2</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">((</span><span class="n">rate2</span> <span class="o">-</span> <span class="n">rate1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">-</span> <span class="n">iter1</span><span class="p">)</span>
                <span class="o">/</span> <span class="p">(</span><span class="n">iter2</span> <span class="o">-</span> <span class="n">iter1</span><span class="p">)</span> <span class="o">+</span> <span class="n">rate1</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">on_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">half_iteration</span><span class="p">:</span>
            <span class="n">rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_interpolate</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">half_iteration</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_rate</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">&lt;</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">half_iteration</span><span class="p">:</span>
            <span class="n">rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_interpolate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">half_iteration</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">half_iteration</span><span class="p">,</span>
                                     <span class="bp">self</span><span class="o">.</span><span class="n">max_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_rate</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_interpolate</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">half_iteration</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">iterations</span><span class="p">,</span>
                                     <span class="bp">self</span><span class="o">.</span><span class="n">start_rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_rate</span><span class="p">)</span>
            <span class="n">rate</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">rate</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iteration</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">K</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">rate</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">25</span>
<span class="n">onecycle</span> <span class="o">=</span> <span class="n">OneCycleScheduler</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="n">max_rate</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span>
                    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">onecycle</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples, validate on 5000 samples
Epoch 1/25
55000/55000 [==============================] - 1s 22us/sample - loss: 0.6576 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.8300
Epoch 2/25
55000/55000 [==============================] - 1s 18us/sample - loss: 0.4587 - accuracy: 0.8387 - val_loss: 0.4316 - val_accuracy: 0.8490
Epoch 3/25
55000/55000 [==============================] - 1s 22us/sample - loss: 0.4119 - accuracy: 0.8560 - val_loss: 0.4117 - val_accuracy: 0.8580
Epoch 4/25
55000/55000 [==============================] - 1s 23us/sample - loss: 0.3842 - accuracy: 0.8657 - val_loss: 0.3920 - val_accuracy: 0.8638
Epoch 5/25
55000/55000 [==============================] - 1s 21us/sample - loss: 0.3636 - accuracy: 0.8708 - val_loss: 0.3739 - val_accuracy: 0.8710
Epoch 6/25
55000/55000 [==============================] - 1s 21us/sample - loss: 0.3460 - accuracy: 0.8767 - val_loss: 0.3742 - val_accuracy: 0.8690
Epoch 7/25
55000/55000 [==============================] - 1s 22us/sample - loss: 0.3312 - accuracy: 0.8818 - val_loss: 0.3760 - val_accuracy: 0.8656
Epoch 8/25
55000/55000 [==============================] - 1s 19us/sample - loss: 0.3194 - accuracy: 0.8846 - val_loss: 0.3583 - val_accuracy: 0.8756
Epoch 9/25
55000/55000 [==============================] - 1s 21us/sample - loss: 0.3056 - accuracy: 0.8902 - val_loss: 0.3474 - val_accuracy: 0.8820
Epoch 10/25
55000/55000 [==============================] - 1s 21us/sample - loss: 0.2943 - accuracy: 0.8937 - val_loss: 0.3993 - val_accuracy: 0.8562
Epoch 11/25
55000/55000 [==============================] - 1s 20us/sample - loss: 0.2845 - accuracy: 0.8957 - val_loss: 0.3446 - val_accuracy: 0.8820
Epoch 12/25
55000/55000 [==============================] - 1s 20us/sample - loss: 0.2720 - accuracy: 0.9020 - val_loss: 0.3348 - val_accuracy: 0.8808
Epoch 13/25
55000/55000 [==============================] - 1s 20us/sample - loss: 0.2536 - accuracy: 0.9094 - val_loss: 0.3386 - val_accuracy: 0.8822
Epoch 14/25
55000/55000 [==============================] - 1s 21us/sample - loss: 0.2420 - accuracy: 0.9125 - val_loss: 0.3313 - val_accuracy: 0.8858
Epoch 15/25
55000/55000 [==============================] - 1s 19us/sample - loss: 0.2288 - accuracy: 0.9174 - val_loss: 0.3241 - val_accuracy: 0.8840
Epoch 16/25
55000/55000 [==============================] - 1s 18us/sample - loss: 0.2169 - accuracy: 0.9222 - val_loss: 0.3342 - val_accuracy: 0.8846
Epoch 17/25
55000/55000 [==============================] - 1s 18us/sample - loss: 0.2067 - accuracy: 0.9264 - val_loss: 0.3208 - val_accuracy: 0.8874
Epoch 18/25
55000/55000 [==============================] - 1s 20us/sample - loss: 0.1977 - accuracy: 0.9301 - val_loss: 0.3186 - val_accuracy: 0.8888
Epoch 19/25
55000/55000 [==============================] - 1s 19us/sample - loss: 0.1892 - accuracy: 0.9329 - val_loss: 0.3278 - val_accuracy: 0.8848
Epoch 20/25
55000/55000 [==============================] - 1s 19us/sample - loss: 0.1818 - accuracy: 0.9375 - val_loss: 0.3195 - val_accuracy: 0.8894
Epoch 21/25
55000/55000 [==============================] - 1s 20us/sample - loss: 0.1756 - accuracy: 0.9395 - val_loss: 0.3163 - val_accuracy: 0.8948
Epoch 22/25
55000/55000 [==============================] - 1s 21us/sample - loss: 0.1701 - accuracy: 0.9416 - val_loss: 0.3177 - val_accuracy: 0.8920
Epoch 23/25
55000/55000 [==============================] - 1s 22us/sample - loss: 0.1657 - accuracy: 0.9441 - val_loss: 0.3168 - val_accuracy: 0.8944
Epoch 24/25
55000/55000 [==============================] - 1s 19us/sample - loss: 0.1629 - accuracy: 0.9454 - val_loss: 0.3167 - val_accuracy: 0.8946
Epoch 25/25
55000/55000 [==============================] - 1s 18us/sample - loss: 0.1611 - accuracy: 0.9465 - val_loss: 0.3170 - val_accuracy: 0.8934
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="avoiding-overfitting-through-regularization">
<h1>Avoiding Overfitting Through Regularization<a class="headerlink" href="#avoiding-overfitting-through-regularization" title="Permalink to this headline">¶</a></h1>
<div class="section" id="ell-1-and-ell-2-regularization">
<h2><span class="math notranslate nohighlight">\(\ell_1\)</span> and <span class="math notranslate nohighlight">\(\ell_2\)</span> regularization<a class="headerlink" href="#ell-1-and-ell-2-regularization" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">layer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;elu&quot;</span><span class="p">,</span>
                           <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;he_normal&quot;</span><span class="p">,</span>
                           <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>
<span class="c1"># or l1(0.1) for ℓ1 regularization with a factor or 0.1</span>
<span class="c1"># or l1_l2(0.1, 0.01) for both ℓ1 and ℓ2 regularization, with factors 0.1 and 0.01 respectively</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;elu&quot;</span><span class="p">,</span>
                       <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;he_normal&quot;</span><span class="p">,</span>
                       <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;elu&quot;</span><span class="p">,</span>
                       <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;he_normal&quot;</span><span class="p">,</span>
                       <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">,</span>
                       <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>
<span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;nadam&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples, validate on 5000 samples
Epoch 1/2
55000/55000 [==============================] - 7s 130us/sample - loss: 1.5735 - accuracy: 0.8126 - val_loss: 0.7327 - val_accuracy: 0.8222
Epoch 2/2
55000/55000 [==============================] - 6s 115us/sample - loss: 0.7186 - accuracy: 0.8260 - val_loss: 0.6929 - val_accuracy: 0.8338
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="n">RegularizedDense</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">,</span>
                           <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;elu&quot;</span><span class="p">,</span>
                           <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;he_normal&quot;</span><span class="p">,</span>
                           <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]),</span>
    <span class="n">RegularizedDense</span><span class="p">(</span><span class="mi">300</span><span class="p">),</span>
    <span class="n">RegularizedDense</span><span class="p">(</span><span class="mi">100</span><span class="p">),</span>
    <span class="n">RegularizedDense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;nadam&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples, validate on 5000 samples
Epoch 1/2
55000/55000 [==============================] - 7s 133us/sample - loss: 1.6006 - accuracy: 0.8129 - val_loss: 0.7374 - val_accuracy: 0.8236
Epoch 2/2
55000/55000 [==============================] - 7s 128us/sample - loss: 0.7179 - accuracy: 0.8265 - val_loss: 0.6905 - val_accuracy: 0.8356
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="dropout">
<h2>Dropout<a class="headerlink" href="#dropout" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;elu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;he_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;elu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;he_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;nadam&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples, validate on 5000 samples
Epoch 1/2
55000/55000 [==============================] - 8s 139us/sample - loss: 0.5856 - accuracy: 0.7992 - val_loss: 0.3908 - val_accuracy: 0.8570
Epoch 2/2
55000/55000 [==============================] - 6s 117us/sample - loss: 0.4260 - accuracy: 0.8443 - val_loss: 0.3389 - val_accuracy: 0.8730
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="alpha-dropout">
<h2>Alpha Dropout<a class="headerlink" href="#alpha-dropout" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">AlphaDropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">AlphaDropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">AlphaDropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">nesterov</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples, validate on 5000 samples
Epoch 1/20
55000/55000 [==============================] - 3s 55us/sample - loss: 0.6616 - accuracy: 0.7616 - val_loss: 0.6682 - val_accuracy: 0.8258
Epoch 2/20
55000/55000 [==============================] - 3s 49us/sample - loss: 0.5526 - accuracy: 0.7969 - val_loss: 0.5835 - val_accuracy: 0.8382
Epoch 3/20
55000/55000 [==============================] - 3s 48us/sample - loss: 0.5259 - accuracy: 0.8060 - val_loss: 0.5312 - val_accuracy: 0.8512
Epoch 4/20
55000/55000 [==============================] - 3s 49us/sample - loss: 0.5076 - accuracy: 0.8111 - val_loss: 0.4969 - val_accuracy: 0.8606
Epoch 5/20
55000/55000 [==============================] - 3s 47us/sample - loss: 0.4929 - accuracy: 0.8175 - val_loss: 0.4875 - val_accuracy: 0.8610
Epoch 6/20
55000/55000 [==============================] - 3s 48us/sample - loss: 0.4844 - accuracy: 0.8190 - val_loss: 0.5141 - val_accuracy: 0.8552
Epoch 7/20
55000/55000 [==============================] - 3s 48us/sample - loss: 0.4716 - accuracy: 0.8258 - val_loss: 0.4474 - val_accuracy: 0.8660
Epoch 8/20
55000/55000 [==============================] - 3s 47us/sample - loss: 0.4643 - accuracy: 0.8272 - val_loss: 0.4535 - val_accuracy: 0.8596
Epoch 9/20
55000/55000 [==============================] - 3s 48us/sample - loss: 0.4574 - accuracy: 0.8302 - val_loss: 0.4602 - val_accuracy: 0.8652
Epoch 10/20
55000/55000 [==============================] - 3s 48us/sample - loss: 0.4500 - accuracy: 0.8345 - val_loss: 0.4225 - val_accuracy: 0.8652
Epoch 11/20
55000/55000 [==============================] - 3s 47us/sample - loss: 0.4484 - accuracy: 0.8334 - val_loss: 0.4461 - val_accuracy: 0.8674
Epoch 12/20
55000/55000 [==============================] - 3s 47us/sample - loss: 0.4466 - accuracy: 0.8341 - val_loss: 0.4461 - val_accuracy: 0.8688
Epoch 13/20
55000/55000 [==============================] - 3s 47us/sample - loss: 0.4402 - accuracy: 0.8377 - val_loss: 0.4570 - val_accuracy: 0.8730
Epoch 14/20
55000/55000 [==============================] - 3s 48us/sample - loss: 0.4336 - accuracy: 0.8390 - val_loss: 0.4867 - val_accuracy: 0.8708
Epoch 15/20
55000/55000 [==============================] - 3s 47us/sample - loss: 0.4324 - accuracy: 0.8404 - val_loss: 0.4342 - val_accuracy: 0.8752
Epoch 16/20
55000/55000 [==============================] - 3s 47us/sample - loss: 0.4292 - accuracy: 0.8395 - val_loss: 0.4934 - val_accuracy: 0.8602
Epoch 17/20
55000/55000 [==============================] - 3s 49us/sample - loss: 0.4294 - accuracy: 0.8390 - val_loss: 0.4297 - val_accuracy: 0.8802
Epoch 18/20
55000/55000 [==============================] - 3s 47us/sample - loss: 0.4230 - accuracy: 0.8435 - val_loss: 0.4425 - val_accuracy: 0.8754
Epoch 19/20
55000/55000 [==============================] - 3s 47us/sample - loss: 0.4242 - accuracy: 0.8425 - val_loss: 0.4083 - val_accuracy: 0.8742
Epoch 20/20
55000/55000 [==============================] - 3s 47us/sample - loss: 0.4201 - accuracy: 0.8450 - val_loss: 0.4256 - val_accuracy: 0.8766
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>10000/10000 [==============================] - 0s 25us/sample - loss: 0.4736 - accuracy: 0.8648
</pre></div>
</div>
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>[0.47358015085458754, 0.8648]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>55000/55000 [==============================] - 1s 22us/sample - loss: 0.3532 - accuracy: 0.8859
</pre></div>
</div>
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>[0.35321958436965945, 0.8859091]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples
55000/55000 [==============================] - 2s 44us/sample - loss: 0.4186 - accuracy: 0.8451
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="mc-dropout">
<h2>MC Dropout<a class="headerlink" href="#mc-dropout" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y_probas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">model</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                     <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)])</span>
<span class="n">y_proba</span> <span class="o">=</span> <span class="n">y_probas</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">y_std</span> <span class="o">=</span> <span class="n">y_probas</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:Layer flatten_18 is casting an input tensor from dtype float64 to the layer&#39;s dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it&#39;s dtype defaults to floatx.

If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.

To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx(&#39;float64&#39;)`. To change just this layer, pass dtype=&#39;float64&#39; to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.

</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">[:</span><span class="mi">1</span><span class="p">]),</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">y_probas</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([[[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.05, 0.  , 0.94]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.17, 0.  , 0.75]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.01, 0.  , 0.8 ]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.03, 0.05, 0.9 ]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.04, 0.  , 0.87]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.05, 0.  , 0.94]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.02, 0.  , 0.97]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.61, 0.  , 0.01, 0.  , 0.38]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.02, 0.  , 0.96]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.33, 0.  , 0.04, 0.  , 0.63]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.06, 0.  , 0.74]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.42, 0.  , 0.09, 0.  , 0.49]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.05, 0.  , 0.83]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.03, 0.  , 0.81]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.  , 0.  , 0.97]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.09, 0.  , 0.83]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.95]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.03, 0.  , 0.87]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.64, 0.  , 0.13, 0.  , 0.22]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.42, 0.  , 0.2 , 0.  , 0.39]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.2 , 0.  , 0.78]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.02, 0.  , 0.95]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.17, 0.  , 0.15, 0.  , 0.67]],

       [[0.  , 0.  , 0.  , 0.01, 0.01, 0.05, 0.08, 0.1 , 0.  , 0.75]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.02, 0.  , 0.92]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.68, 0.  , 0.06, 0.  , 0.26]],

       [[0.  , 0.  , 0.  , 0.  , 0.01, 0.12, 0.  , 0.15, 0.06, 0.66]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.99]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.35, 0.  , 0.01, 0.  , 0.65]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.28, 0.  , 0.48]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.03, 0.  , 0.94]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.53, 0.  , 0.4 ]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.03, 0.  , 0.93]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.09, 0.  , 0.89]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.36, 0.  , 0.  , 0.  , 0.63]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.02, 0.  , 0.92]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.27, 0.  , 0.04, 0.  , 0.68]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.01, 0.  , 0.94]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.11, 0.01, 0.86]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.75]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.99]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.9 , 0.  , 0.01, 0.  , 0.09]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.04, 0.  , 0.83]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.01, 0.  , 0.95]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.47, 0.  , 0.  , 0.  , 0.52]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.98]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.96]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.08, 0.  , 0.77]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.04, 0.  , 0.92]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.22, 0.  , 0.04, 0.  , 0.74]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.1 , 0.  , 0.86]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.03, 0.  , 0.89]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.97]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.07, 0.  , 0.83]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.16, 0.01, 0.79]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.62, 0.  , 0.04, 0.  , 0.35]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.98]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.04, 0.04, 0.91]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.96]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.29, 0.  , 0.04, 0.  , 0.67]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.33, 0.  , 0.04, 0.  , 0.63]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.  , 0.  , 0.98]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.98]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.27, 0.  , 0.72]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.99]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.2 , 0.  , 0.76]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.01, 0.  , 0.95]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.3 , 0.  , 0.68]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.09, 0.  , 0.9 ]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.96, 0.  , 0.02, 0.  , 0.02]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.04, 0.  , 0.84]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.97]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.06, 0.  , 0.78]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.01, 0.  , 0.81]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.31, 0.  , 0.25, 0.01, 0.43]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.11, 0.  , 0.83]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.01, 0.  , 0.98]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.08, 0.  , 0.85]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.02, 0.01, 0.95]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.  , 0.  , 0.94]],

       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.41, 0.  , 0.02, 0.  , 0.56]]],
      dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">y_proba</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.06, 0.  , 0.81]],
      dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y_std</span> <span class="o">=</span> <span class="n">y_probas</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">y_std</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.01, 0.08, 0.01, 0.21]],
      dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_proba</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
<span class="n">accuracy</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>0.8606
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MCDropout</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">MCAlphaDropout</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">AlphaDropout</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mc_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">MCAlphaDropout</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">rate</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">AlphaDropout</span><span class="p">)</span> <span class="k">else</span> <span class="n">layer</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mc_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Model: &quot;sequential_20&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_18 (Flatten)         (None, 784)               0         
_________________________________________________________________
mc_alpha_dropout (MCAlphaDro (None, 784)               0         
_________________________________________________________________
dense_262 (Dense)            (None, 300)               235500    
_________________________________________________________________
mc_alpha_dropout_1 (MCAlphaD (None, 300)               0         
_________________________________________________________________
dense_263 (Dense)            (None, 100)               30100     
_________________________________________________________________
mc_alpha_dropout_2 (MCAlphaD (None, 100)               0         
_________________________________________________________________
dense_264 (Dense)            (None, 10)                1010      
=================================================================
Total params: 266,610
Trainable params: 266,610
Non-trainable params: 0
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">nesterov</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">mc_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mc_model</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can use the model with MC Dropout:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">mc_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">[:</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.07, 0.01, 0.79]],
      dtype=float32)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="max-norm">
<h2>Max norm<a class="headerlink" href="#max-norm" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">layer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">,</span>
                           <span class="n">kernel_constraint</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">constraints</span><span class="o">.</span><span class="n">max_norm</span><span class="p">(</span><span class="mf">1.</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">MaxNormDense</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">,</span>
                       <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">,</span>
                       <span class="n">kernel_constraint</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">constraints</span><span class="o">.</span><span class="n">max_norm</span><span class="p">(</span><span class="mf">1.</span><span class="p">))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]),</span>
    <span class="n">MaxNormDense</span><span class="p">(</span><span class="mi">300</span><span class="p">),</span>
    <span class="n">MaxNormDense</span><span class="p">(</span><span class="mi">100</span><span class="p">),</span>
    <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;nadam&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 55000 samples, validate on 5000 samples
Epoch 1/2
55000/55000 [==============================] - 6s 114us/sample - loss: 0.4734 - accuracy: 0.8364 - val_loss: 0.3999 - val_accuracy: 0.8614
Epoch 2/2
55000/55000 [==============================] - 6s 100us/sample - loss: 0.3583 - accuracy: 0.8685 - val_loss: 0.3494 - val_accuracy: 0.8746
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="exercises">
<h1>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h1>
<div class="section" id="to-7">
<h2>1. to 7.<a class="headerlink" href="#to-7" title="Permalink to this headline">¶</a></h2>
<p>See appendix A.</p>
</div>
<div class="section" id="deep-learning-on-cifar10">
<h2>8. Deep Learning on CIFAR10<a class="headerlink" href="#deep-learning-on-cifar10" title="Permalink to this headline">¶</a></h2>
<div class="section" id="a">
<h3>a.<a class="headerlink" href="#a" title="Permalink to this headline">¶</a></h3>
<p><em>Exercise: Build a DNN with 20 hidden layers of 100 neurons each (that’s too many, but it’s the point of this exercise). Use He initialization and the ELU activation function.</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span>
                                 <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;elu&quot;</span><span class="p">,</span>
                                 <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;he_normal&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="b">
<h3>b.<a class="headerlink" href="#b" title="Permalink to this headline">¶</a></h3>
<p><em>Exercise: Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with <code class="docutils literal notranslate"><span class="pre">keras.datasets.cifar10.load_data()</span></code>. The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you’ll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model’s architecture or hyperparameters.</em></p>
<p>Let’s add the output layer to the model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s use a Nadam optimizer with a learning rate of 5e-5. I tried learning rates 1e-5, 3e-5, 1e-4, 3e-4, 1e-3, 3e-3 and 1e-2, and I compared their learning curves for 10 epochs each (using the TensorBoard callback, below). The learning rates 3e-5 and 1e-4 were pretty good, so I tried 5e-5, which turned out to be slightly better.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Nadam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s load the CIFAR10 dataset. We also want to use early stopping, so we need a validation set. Let’s use the first 5,000 images of the original training set as the validation set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">X_train_full</span><span class="p">,</span> <span class="n">y_train_full</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train_full</span><span class="p">[</span><span class="mi">5000</span><span class="p">:]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train_full</span><span class="p">[</span><span class="mi">5000</span><span class="p">:]</span>
<span class="n">X_valid</span> <span class="o">=</span> <span class="n">X_train_full</span><span class="p">[:</span><span class="mi">5000</span><span class="p">]</span>
<span class="n">y_valid</span> <span class="o">=</span> <span class="n">y_train_full</span><span class="p">[:</span><span class="mi">5000</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can create the callbacks we need and train the model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">early_stopping_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">model_checkpoint_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="s2">&quot;my_cifar10_model.h5&quot;</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">run_index</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># increment every time you train the model</span>
<span class="n">run_logdir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">curdir</span><span class="p">,</span> <span class="s2">&quot;my_cifar10_logs&quot;</span><span class="p">,</span> <span class="s2">&quot;run_</span><span class="si">{:03d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">run_index</span><span class="p">))</span>
<span class="n">tensorboard_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">TensorBoard</span><span class="p">(</span><span class="n">run_logdir</span><span class="p">)</span>
<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">early_stopping_cb</span><span class="p">,</span> <span class="n">model_checkpoint_cb</span><span class="p">,</span> <span class="n">tensorboard_cb</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">tensorboard</span> <span class="o">--</span><span class="n">logdir</span><span class="o">=./</span><span class="n">my_cifar10_logs</span> <span class="o">--</span><span class="n">port</span><span class="o">=</span><span class="mi">6006</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe id="tensorboard-frame-71944bb8fa193bc4" width="100%" height="800" frameborder="0">
</iframe>
<script>
  (function() {
    const frame = document.getElementById("tensorboard-frame-71944bb8fa193bc4");
    const url = new URL("/", window.location);
    url.port = 6006;
    frame.src = url;
  })();
</script>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span>
          <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 45000 samples, validate on 5000 samples
Epoch 1/100
45000/45000 [==============================] - 9s 208us/sample - loss: 4.0892 - accuracy: 0.1672 - val_loss: 2.1601 - val_accuracy: 0.2020
Epoch 2/100
45000/45000 [==============================] - 8s 175us/sample - loss: 2.0558 - accuracy: 0.2469 - val_loss: 1.9845 - val_accuracy: 0.2808
Epoch 3/100
45000/45000 [==============================] - 7s 161us/sample - loss: 1.9306 - accuracy: 0.2942 - val_loss: 1.9089 - val_accuracy: 0.2934
Epoch 4/100
45000/45000 [==============================] - 7s 157us/sample - loss: 1.8437 - accuracy: 0.3332 - val_loss: 1.7957 - val_accuracy: 0.3510
Epoch 5/100
45000/45000 [==============================] - 7s 162us/sample - loss: 1.7829 - accuracy: 0.3560 - val_loss: 1.7779 - val_accuracy: 0.3582
Epoch 6/100
45000/45000 [==============================] - 7s 154us/sample - loss: 1.7374 - accuracy: 0.3702 - val_loss: 1.8059 - val_accuracy: 0.3540
Epoch 7/100
45000/45000 [==============================] - 8s 171us/sample - loss: 1.6938 - accuracy: 0.3881 - val_loss: 1.7060 - val_accuracy: 0.3796
Epoch 8/100
45000/45000 [==============================] - 8s 174us/sample - loss: 1.6624 - accuracy: 0.4014 - val_loss: 1.7063 - val_accuracy: 0.3806
Epoch 9/100
45000/45000 [==============================] - 8s 180us/sample - loss: 1.6328 - accuracy: 0.4108 - val_loss: 1.6685 - val_accuracy: 0.4108
Epoch 10/100
45000/45000 [==============================] - 8s 176us/sample - loss: 1.6090 - accuracy: 0.4192 - val_loss: 1.6384 - val_accuracy: 0.4046
Epoch 11/100
45000/45000 [==============================] - 8s 172us/sample - loss: 1.5826 - accuracy: 0.4304 - val_loss: 1.6340 - val_accuracy: 0.4084
Epoch 12/100
45000/45000 [==============================] - 9s 194us/sample - loss: 1.5638 - accuracy: 0.4374 - val_loss: 1.6190 - val_accuracy: 0.4134
Epoch 13/100
45000/45000 [==============================] - 9s 197us/sample - loss: 1.5454 - accuracy: 0.4459 - val_loss: 1.5927 - val_accuracy: 0.4326
Epoch 14/100
45000/45000 [==============================] - 9s 196us/sample - loss: 1.5266 - accuracy: 0.4523 - val_loss: 1.6527 - val_accuracy: 0.4210
Epoch 15/100
45000/45000 [==============================] - 9s 203us/sample - loss: 1.5140 - accuracy: 0.4534 - val_loss: 1.5902 - val_accuracy: 0.4352
Epoch 16/100
45000/45000 [==============================] - 9s 196us/sample - loss: 1.4965 - accuracy: 0.4622 - val_loss: 1.6270 - val_accuracy: 0.4146
Epoch 17/100
45000/45000 [==============================] - 9s 199us/sample - loss: 1.4846 - accuracy: 0.4677 - val_loss: 1.6368 - val_accuracy: 0.4066
&lt;&lt;49 more lines&gt;&gt;
45000/45000 [==============================] - 10s 214us/sample - loss: 1.2420 - accuracy: 0.5531 - val_loss: 1.5280 - val_accuracy: 0.4594
Epoch 43/100
45000/45000 [==============================] - 10s 223us/sample - loss: 1.2347 - accuracy: 0.5564 - val_loss: 1.5307 - val_accuracy: 0.4692
Epoch 44/100
45000/45000 [==============================] - 10s 222us/sample - loss: 1.2271 - accuracy: 0.5579 - val_loss: 1.5747 - val_accuracy: 0.4626
Epoch 45/100
45000/45000 [==============================] - 10s 217us/sample - loss: 1.2224 - accuracy: 0.5587 - val_loss: 1.5249 - val_accuracy: 0.4678
Epoch 46/100
45000/45000 [==============================] - 10s 217us/sample - loss: 1.2108 - accuracy: 0.5636 - val_loss: 1.5235 - val_accuracy: 0.4786
Epoch 47/100
45000/45000 [==============================] - 10s 219us/sample - loss: 1.2049 - accuracy: 0.5655 - val_loss: 1.5776 - val_accuracy: 0.4594
Epoch 48/100
45000/45000 [==============================] - 10s 211us/sample - loss: 1.1984 - accuracy: 0.5687 - val_loss: 1.5269 - val_accuracy: 0.4690
Epoch 49/100
45000/45000 [==============================] - 10s 216us/sample - loss: 1.1893 - accuracy: 0.5736 - val_loss: 1.5449 - val_accuracy: 0.4682
Epoch 50/100
45000/45000 [==============================] - 10s 213us/sample - loss: 1.1850 - accuracy: 0.5741 - val_loss: 1.5345 - val_accuracy: 0.4800
Epoch 51/100
45000/45000 [==============================] - 9s 205us/sample - loss: 1.1772 - accuracy: 0.5749 - val_loss: 1.5430 - val_accuracy: 0.4660
Epoch 52/100
45000/45000 [==============================] - 10s 216us/sample - loss: 1.1701 - accuracy: 0.5777 - val_loss: 1.5470 - val_accuracy: 0.4684
Epoch 53/100
45000/45000 [==============================] - 10s 217us/sample - loss: 1.1628 - accuracy: 0.5802 - val_loss: 1.6219 - val_accuracy: 0.4622
Epoch 54/100
45000/45000 [==============================] - 10s 228us/sample - loss: 1.1582 - accuracy: 0.5820 - val_loss: 1.5455 - val_accuracy: 0.4778
Epoch 55/100
45000/45000 [==============================] - 10s 222us/sample - loss: 1.1499 - accuracy: 0.5866 - val_loss: 1.6274 - val_accuracy: 0.4534
Epoch 56/100
45000/45000 [==============================] - 10s 222us/sample - loss: 1.1451 - accuracy: 0.5893 - val_loss: 1.5577 - val_accuracy: 0.4736
Epoch 57/100
45000/45000 [==============================] - 10s 223us/sample - loss: 1.1406 - accuracy: 0.5903 - val_loss: 1.6167 - val_accuracy: 0.4610
Epoch 58/100
45000/45000 [==============================] - 10s 231us/sample - loss: 1.1372 - accuracy: 0.5896 - val_loss: 1.6059 - val_accuracy: 0.4564
Epoch 59/100
45000/45000 [==============================] - 10s 229us/sample - loss: 1.1271 - accuracy: 0.5938 - val_loss: 1.5618 - val_accuracy: 0.4660
</pre></div>
</div>
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;tensorflow.python.keras.callbacks.History at 0x7fb37881c5c0&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;my_cifar10_model.h5&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>5000/5000 [==============================] - 0s 65us/sample - loss: 1.5099 - accuracy: 0.4736
</pre></div>
</div>
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>[1.5099372177124024, 0.4736]
</pre></div>
</div>
</div>
</div>
<p>The model with the lowest validation loss gets about 47% accuracy on the validation set. It took 39 epochs to reach the lowest validation loss, with roughly 10 seconds per epoch on my laptop (without a GPU). Let’s see if we can improve performance using Batch Normalization.</p>
</div>
<div class="section" id="c">
<h3>c.<a class="headerlink" href="#c" title="Permalink to this headline">¶</a></h3>
<p><em>Exercise: Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before? Does it produce a better model? How does it affect training speed?</em></p>
<p>The code below is very similar to the code above, with a few changes:</p>
<ul class="simple">
<li><p>I added a BN layer after every Dense layer (before the activation function), except for the output layer. I also added a BN layer before the first hidden layer.</p></li>
<li><p>I changed the learning rate to 5e-4. I experimented with 1e-5, 3e-5, 5e-5, 1e-4, 3e-4, 5e-4, 1e-3 and 3e-3, and I chose the one with the best validation performance after 20 epochs.</p></li>
<li><p>I renamed the run directories to run_bn_* and the model file name to my_cifar10_bn_model.h5.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">())</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;he_normal&quot;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">())</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="s2">&quot;elu&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Nadam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>

<span class="n">early_stopping_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">model_checkpoint_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="s2">&quot;my_cifar10_bn_model.h5&quot;</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">run_index</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># increment every time you train the model</span>
<span class="n">run_logdir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">curdir</span><span class="p">,</span> <span class="s2">&quot;my_cifar10_logs&quot;</span><span class="p">,</span> <span class="s2">&quot;run_bn_</span><span class="si">{:03d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">run_index</span><span class="p">))</span>
<span class="n">tensorboard_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">TensorBoard</span><span class="p">(</span><span class="n">run_logdir</span><span class="p">)</span>
<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">early_stopping_cb</span><span class="p">,</span> <span class="n">model_checkpoint_cb</span><span class="p">,</span> <span class="n">tensorboard_cb</span><span class="p">]</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span>
          <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;my_cifar10_bn_model.h5&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 45000 samples, validate on 5000 samples
Epoch 1/100
45000/45000 [==============================] - 21s 466us/sample - loss: 1.8365 - accuracy: 0.3390 - val_loss: 1.6330 - val_accuracy: 0.4174
Epoch 2/100
45000/45000 [==============================] - 16s 352us/sample - loss: 1.6623 - accuracy: 0.4063 - val_loss: 1.5967 - val_accuracy: 0.4204
Epoch 3/100
45000/45000 [==============================] - 16s 355us/sample - loss: 1.5946 - accuracy: 0.4314 - val_loss: 1.5225 - val_accuracy: 0.4602
Epoch 4/100
45000/45000 [==============================] - 17s 367us/sample - loss: 1.5417 - accuracy: 0.4551 - val_loss: 1.4680 - val_accuracy: 0.4756
Epoch 5/100
45000/45000 [==============================] - 17s 367us/sample - loss: 1.5013 - accuracy: 0.4678 - val_loss: 1.4378 - val_accuracy: 0.4862
Epoch 6/100
45000/45000 [==============================] - 16s 361us/sample - loss: 1.4637 - accuracy: 0.4797 - val_loss: 1.4221 - val_accuracy: 0.4982
Epoch 7/100
45000/45000 [==============================] - 16s 355us/sample - loss: 1.4361 - accuracy: 0.4921 - val_loss: 1.4133 - val_accuracy: 0.4968
Epoch 8/100
45000/45000 [==============================] - 15s 326us/sample - loss: 1.4078 - accuracy: 0.4998 - val_loss: 1.3916 - val_accuracy: 0.5040
Epoch 9/100
45000/45000 [==============================] - 14s 315us/sample - loss: 1.3811 - accuracy: 0.5104 - val_loss: 1.3695 - val_accuracy: 0.5116
Epoch 10/100
45000/45000 [==============================] - 14s 318us/sample - loss: 1.3571 - accuracy: 0.5205 - val_loss: 1.3701 - val_accuracy: 0.5112
Epoch 11/100
45000/45000 [==============================] - 15s 329us/sample - loss: 1.3367 - accuracy: 0.5246 - val_loss: 1.3549 - val_accuracy: 0.5196
Epoch 12/100
45000/45000 [==============================] - 14s 316us/sample - loss: 1.3158 - accuracy: 0.5322 - val_loss: 1.4038 - val_accuracy: 0.5048
Epoch 13/100
45000/45000 [==============================] - 15s 328us/sample - loss: 1.3028 - accuracy: 0.5392 - val_loss: 1.3453 - val_accuracy: 0.5242
Epoch 14/100
45000/45000 [==============================] - 15s 331us/sample - loss: 1.2798 - accuracy: 0.5460 - val_loss: 1.3427 - val_accuracy: 0.5218
Epoch 15/100
45000/45000 [==============================] - 15s 327us/sample - loss: 1.2642 - accuracy: 0.5502 - val_loss: 1.3802 - val_accuracy: 0.5072
Epoch 16/100
45000/45000 [==============================] - 15s 336us/sample - loss: 1.2497 - accuracy: 0.5592 - val_loss: 1.3870 - val_accuracy: 0.5154
Epoch 17/100
45000/45000 [==============================] - 15s 332us/sample - loss: 1.2339 - accuracy: 0.5645 - val_loss: 1.3270 - val_accuracy: 0.5366
Epoch 18/100
45000/45000 [==============================] - 15s 331us/sample - loss: 1.2223 - accuracy: 0.5688 - val_loss: 1.3054 - val_accuracy: 0.5506
Epoch 19/100
45000/45000 [==============================] - 15s 339us/sample - loss: 1.2015 - accuracy: 0.5750 - val_loss: 1.3134 - val_accuracy: 0.5462
Epoch 20/100
45000/45000 [==============================] - 15s 326us/sample - loss: 1.1884 - accuracy: 0.5796 - val_loss: 1.3459 - val_accuracy: 0.5252
Epoch 21/100
45000/45000 [==============================] - 17s 370us/sample - loss: 1.1767 - accuracy: 0.5876 - val_loss: 1.3404 - val_accuracy: 0.5392
Epoch 22/100
45000/45000 [==============================] - 16s 366us/sample - loss: 1.1679 - accuracy: 0.5872 - val_loss: 1.3600 - val_accuracy: 0.5332
Epoch 23/100
45000/45000 [==============================] - 15s 337us/sample - loss: 1.1513 - accuracy: 0.5954 - val_loss: 1.3148 - val_accuracy: 0.5498
Epoch 24/100
45000/45000 [==============================] - 16s 346us/sample - loss: 1.1345 - accuracy: 0.6033 - val_loss: 1.3290 - val_accuracy: 0.5368
Epoch 25/100
45000/45000 [==============================] - 16s 350us/sample - loss: 1.1252 - accuracy: 0.6025 - val_loss: 1.3350 - val_accuracy: 0.5434
Epoch 26/100
45000/45000 [==============================] - 15s 341us/sample - loss: 1.1192 - accuracy: 0.6070 - val_loss: 1.3423 - val_accuracy: 0.5364
Epoch 27/100
45000/45000 [==============================] - 15s 342us/sample - loss: 1.1028 - accuracy: 0.6093 - val_loss: 1.3511 - val_accuracy: 0.5358
Epoch 28/100
45000/45000 [==============================] - 15s 332us/sample - loss: 1.0907 - accuracy: 0.6158 - val_loss: 1.3706 - val_accuracy: 0.5350
Epoch 29/100
45000/45000 [==============================] - 16s 345us/sample - loss: 1.0785 - accuracy: 0.6197 - val_loss: 1.3356 - val_accuracy: 0.5398
Epoch 30/100
45000/45000 [==============================] - 16s 352us/sample - loss: 1.0718 - accuracy: 0.6198 - val_loss: 1.3529 - val_accuracy: 0.5446
Epoch 31/100
45000/45000 [==============================] - 15s 333us/sample - loss: 1.0629 - accuracy: 0.6259 - val_loss: 1.3590 - val_accuracy: 0.5434
Epoch 32/100
45000/45000 [==============================] - 15s 331us/sample - loss: 1.0504 - accuracy: 0.6292 - val_loss: 1.3448 - val_accuracy: 0.5388
Epoch 33/100
45000/45000 [==============================] - 15s 325us/sample - loss: 1.0420 - accuracy: 0.6318 - val_loss: 1.3790 - val_accuracy: 0.5350
Epoch 34/100
45000/45000 [==============================] - 16s 346us/sample - loss: 1.0304 - accuracy: 0.6362 - val_loss: 1.3621 - val_accuracy: 0.5430
Epoch 35/100
45000/45000 [==============================] - 16s 356us/sample - loss: 1.0280 - accuracy: 0.6362 - val_loss: 1.3673 - val_accuracy: 0.5366
Epoch 36/100
45000/45000 [==============================] - 16s 354us/sample - loss: 1.0100 - accuracy: 0.6439 - val_loss: 1.3659 - val_accuracy: 0.5420
Epoch 37/100
45000/45000 [==============================] - 15s 329us/sample - loss: 1.0060 - accuracy: 0.6473 - val_loss: 1.3773 - val_accuracy: 0.5398
Epoch 38/100
45000/45000 [==============================] - 15s 332us/sample - loss: 0.9966 - accuracy: 0.6496 - val_loss: 1.3946 - val_accuracy: 0.5340
5000/5000 [==============================] - 1s 157us/sample - loss: 1.3054 - accuracy: 0.5506
</pre></div>
</div>
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>[1.305354326057434, 0.5506]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><em>Is the model converging faster than before?</em> Much faster! The previous model took 39 epochs to reach the lowest validation loss, while the new model with BN took 18 epochs. That’s more than twice as fast as the previous model. The BN layers stabilized training and allowed us to use a much larger learning rate, so convergence was faster.</p></li>
<li><p><em>Does BN produce a better model?</em> Yes! The final model is also much better, with 55% accuracy instead of 47%. It’s still not a very good model, but at least it’s much better than before (a Convolutional Neural Network would do much better, but that’s a different topic, see chapter 14).</p></li>
<li><p><em>How does BN affect training speed?</em> Although the model converged twice as fast, each epoch took about 16s instead of 10s, because of the extra computations required by the BN layers. So overall, although the number of epochs was reduced by 50%, the training time (wall time) was shortened by 30%. Which is still pretty significant!</p></li>
</ul>
</div>
<div class="section" id="d">
<h3>d.<a class="headerlink" href="#d" title="Permalink to this headline">¶</a></h3>
<p><em>Exercise: Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network self-normalizes (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.).</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span>
                                 <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">,</span>
                                 <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Nadam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">7e-4</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>

<span class="n">early_stopping_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">model_checkpoint_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="s2">&quot;my_cifar10_selu_model.h5&quot;</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">run_index</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># increment every time you train the model</span>
<span class="n">run_logdir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">curdir</span><span class="p">,</span> <span class="s2">&quot;my_cifar10_logs&quot;</span><span class="p">,</span> <span class="s2">&quot;run_selu_</span><span class="si">{:03d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">run_index</span><span class="p">))</span>
<span class="n">tensorboard_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">TensorBoard</span><span class="p">(</span><span class="n">run_logdir</span><span class="p">)</span>
<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">early_stopping_cb</span><span class="p">,</span> <span class="n">model_checkpoint_cb</span><span class="p">,</span> <span class="n">tensorboard_cb</span><span class="p">]</span>

<span class="n">X_means</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_stds</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_train</span> <span class="o">-</span> <span class="n">X_means</span><span class="p">)</span> <span class="o">/</span> <span class="n">X_stds</span>
<span class="n">X_valid_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_valid</span> <span class="o">-</span> <span class="n">X_means</span><span class="p">)</span> <span class="o">/</span> <span class="n">X_stds</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_test</span> <span class="o">-</span> <span class="n">X_means</span><span class="p">)</span> <span class="o">/</span> <span class="n">X_stds</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span>
          <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;my_cifar10_selu_model.h5&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 45000 samples, validate on 5000 samples
Epoch 1/100
45000/45000 [==============================] - 12s 268us/sample - loss: 1.9310 - accuracy: 0.3055 - val_loss: 1.7814 - val_accuracy: 0.3566
Epoch 2/100
45000/45000 [==============================] - 10s 216us/sample - loss: 1.7077 - accuracy: 0.3935 - val_loss: 1.9245 - val_accuracy: 0.3654
Epoch 3/100
45000/45000 [==============================] - 10s 219us/sample - loss: 1.6116 - accuracy: 0.4314 - val_loss: 1.6612 - val_accuracy: 0.4316
Epoch 4/100
45000/45000 [==============================] - 10s 219us/sample - loss: 1.5385 - accuracy: 0.4590 - val_loss: 1.5879 - val_accuracy: 0.4414
Epoch 5/100
45000/45000 [==============================] - 11s 234us/sample - loss: 1.4911 - accuracy: 0.4746 - val_loss: 1.5470 - val_accuracy: 0.4626
Epoch 6/100
45000/45000 [==============================] - 9s 205us/sample - loss: 1.4419 - accuracy: 0.4964 - val_loss: 1.5535 - val_accuracy: 0.4662
Epoch 7/100
45000/45000 [==============================] - 9s 192us/sample - loss: 1.3981 - accuracy: 0.5112 - val_loss: 1.5027 - val_accuracy: 0.4772
Epoch 8/100
45000/45000 [==============================] - 9s 196us/sample - loss: 1.3598 - accuracy: 0.5258 - val_loss: 1.5501 - val_accuracy: 0.4762
Epoch 9/100
45000/45000 [==============================] - 9s 207us/sample - loss: 1.3212 - accuracy: 0.5420 - val_loss: 1.5219 - val_accuracy: 0.4858
Epoch 10/100
45000/45000 [==============================] - 10s 232us/sample - loss: 1.2949 - accuracy: 0.5514 - val_loss: 1.4786 - val_accuracy: 0.4968
Epoch 11/100
45000/45000 [==============================] - 10s 228us/sample - loss: 1.2686 - accuracy: 0.5620 - val_loss: 1.4878 - val_accuracy: 0.4994
Epoch 12/100
45000/45000 [==============================] - 9s 210us/sample - loss: 1.2334 - accuracy: 0.5747 - val_loss: 1.5364 - val_accuracy: 0.4926
Epoch 13/100
45000/45000 [==============================] - 10s 215us/sample - loss: 1.2144 - accuracy: 0.5812 - val_loss: 1.4626 - val_accuracy: 0.5140
Epoch 14/100
45000/45000 [==============================] - 10s 216us/sample - loss: 1.1909 - accuracy: 0.5906 - val_loss: 1.4844 - val_accuracy: 0.5078
Epoch 15/100
45000/45000 [==============================] - 10s 221us/sample - loss: 1.1606 - accuracy: 0.5990 - val_loss: 1.5233 - val_accuracy: 0.4972
Epoch 16/100
45000/45000 [==============================] - 10s 221us/sample - loss: 1.1447 - accuracy: 0.6077 - val_loss: 1.4782 - val_accuracy: 0.5060
Epoch 17/100
45000/45000 [==============================] - 10s 221us/sample - loss: 1.1154 - accuracy: 0.6176 - val_loss: 1.4666 - val_accuracy: 0.5162
Epoch 18/100
45000/45000 [==============================] - 10s 212us/sample - loss: 1.0949 - accuracy: 0.6258 - val_loss: 1.4978 - val_accuracy: 0.5108
Epoch 19/100
45000/45000 [==============================] - 9s 207us/sample - loss: 1.0778 - accuracy: 0.6321 - val_loss: 1.5461 - val_accuracy: 0.5130
Epoch 20/100
45000/45000 [==============================] - 9s 210us/sample - loss: 1.0552 - accuracy: 0.6406 - val_loss: 1.5072 - val_accuracy: 0.5190
Epoch 21/100
45000/45000 [==============================] - 9s 207us/sample - loss: 1.0361 - accuracy: 0.6492 - val_loss: 1.4997 - val_accuracy: 0.5126
Epoch 22/100
45000/45000 [==============================] - 9s 209us/sample - loss: 1.0229 - accuracy: 0.6517 - val_loss: 1.5663 - val_accuracy: 0.5066
Epoch 23/100
45000/45000 [==============================] - 9s 202us/sample - loss: 1.0040 - accuracy: 0.6560 - val_loss: 1.5809 - val_accuracy: 0.5098
Epoch 24/100
45000/45000 [==============================] - 9s 200us/sample - loss: 0.9848 - accuracy: 0.6656 - val_loss: 1.5104 - val_accuracy: 0.5122
Epoch 25/100
45000/45000 [==============================] - 9s 206us/sample - loss: 0.9657 - accuracy: 0.6743 - val_loss: 1.6135 - val_accuracy: 0.5196
Epoch 26/100
45000/45000 [==============================] - 9s 206us/sample - loss: 0.9530 - accuracy: 0.6764 - val_loss: 1.6536 - val_accuracy: 0.5070
Epoch 27/100
45000/45000 [==============================] - 9s 206us/sample - loss: 0.9296 - accuracy: 0.6857 - val_loss: 1.6331 - val_accuracy: 0.5162
Epoch 28/100
45000/45000 [==============================] - 9s 204us/sample - loss: 0.9220 - accuracy: 0.6887 - val_loss: 1.5864 - val_accuracy: 0.5104
Epoch 29/100
45000/45000 [==============================] - 9s 201us/sample - loss: 0.9126 - accuracy: 0.6907 - val_loss: 1.6421 - val_accuracy: 0.5106
Epoch 30/100
45000/45000 [==============================] - 9s 201us/sample - loss: 0.9011 - accuracy: 0.6963 - val_loss: 1.6751 - val_accuracy: 0.5088
Epoch 31/100
45000/45000 [==============================] - 9s 206us/sample - loss: 1.4447 - accuracy: 0.5958 - val_loss: 1.5772 - val_accuracy: 0.4806
Epoch 32/100
45000/45000 [==============================] - 9s 206us/sample - loss: 1.1083 - accuracy: 0.6158 - val_loss: 1.6008 - val_accuracy: 0.4988
Epoch 33/100
45000/45000 [==============================] - 9s 207us/sample - loss: 1.0031 - accuracy: 0.6533 - val_loss: 1.6117 - val_accuracy: 0.5120
5000/5000 [==============================] - 0s 66us/sample - loss: 1.4626 - accuracy: 0.5140
</pre></div>
</div>
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>[1.462584439086914, 0.514]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;my_cifar10_selu_model.h5&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>5000/5000 [==============================] - 0s 74us/sample - loss: 1.4626 - accuracy: 0.5140
</pre></div>
</div>
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>[1.462584439086914, 0.514]
</pre></div>
</div>
</div>
</div>
<p>We get 51.4% accuracy, which is better than the original model, but not quite as good as the model using batch normalization. Moreover, it took 13 epochs to reach the best model, which is much faster than both the original model and the BN model, plus each epoch took only 10 seconds, just like the original model. So it’s by far the fastest model to train (both in terms of epochs and wall time).</p>
</div>
<div class="section" id="e">
<h3>e.<a class="headerlink" href="#e" title="Permalink to this headline">¶</a></h3>
<p><em>Exercise: Try regularizing the model with alpha dropout. Then, without retraining your model, see if you can achieve better accuracy using MC Dropout.</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span>
                                 <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">,</span>
                                 <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">AlphaDropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Nadam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>

<span class="n">early_stopping_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">model_checkpoint_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="s2">&quot;my_cifar10_alpha_dropout_model.h5&quot;</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">run_index</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># increment every time you train the model</span>
<span class="n">run_logdir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">curdir</span><span class="p">,</span> <span class="s2">&quot;my_cifar10_logs&quot;</span><span class="p">,</span> <span class="s2">&quot;run_alpha_dropout_</span><span class="si">{:03d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">run_index</span><span class="p">))</span>
<span class="n">tensorboard_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">TensorBoard</span><span class="p">(</span><span class="n">run_logdir</span><span class="p">)</span>
<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">early_stopping_cb</span><span class="p">,</span> <span class="n">model_checkpoint_cb</span><span class="p">,</span> <span class="n">tensorboard_cb</span><span class="p">]</span>

<span class="n">X_means</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_stds</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_train</span> <span class="o">-</span> <span class="n">X_means</span><span class="p">)</span> <span class="o">/</span> <span class="n">X_stds</span>
<span class="n">X_valid_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_valid</span> <span class="o">-</span> <span class="n">X_means</span><span class="p">)</span> <span class="o">/</span> <span class="n">X_stds</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_test</span> <span class="o">-</span> <span class="n">X_means</span><span class="p">)</span> <span class="o">/</span> <span class="n">X_stds</span>

<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span>
          <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;my_cifar10_alpha_dropout_model.h5&quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 45000 samples, validate on 5000 samples
Epoch 1/100
45000/45000 [==============================] - 12s 263us/sample - loss: 1.8763 - accuracy: 0.3330 - val_loss: 1.7595 - val_accuracy: 0.3668
Epoch 2/100
45000/45000 [==============================] - 10s 219us/sample - loss: 1.6527 - accuracy: 0.4148 - val_loss: 1.7666 - val_accuracy: 0.3808
Epoch 3/100
45000/45000 [==============================] - 10s 219us/sample - loss: 1.5682 - accuracy: 0.4439 - val_loss: 1.6393 - val_accuracy: 0.4490
Epoch 4/100
45000/45000 [==============================] - 10s 211us/sample - loss: 1.5030 - accuracy: 0.4698 - val_loss: 1.6028 - val_accuracy: 0.4466
Epoch 5/100
45000/45000 [==============================] - 9s 209us/sample - loss: 1.4430 - accuracy: 0.4913 - val_loss: 1.5394 - val_accuracy: 0.4562
Epoch 6/100
45000/45000 [==============================] - 10s 215us/sample - loss: 1.4005 - accuracy: 0.5084 - val_loss: 1.5408 - val_accuracy: 0.4818
Epoch 7/100
45000/45000 [==============================] - 10s 216us/sample - loss: 1.3541 - accuracy: 0.5298 - val_loss: 1.5236 - val_accuracy: 0.4866
Epoch 8/100
45000/45000 [==============================] - 10s 214us/sample - loss: 1.3189 - accuracy: 0.5405 - val_loss: 1.5174 - val_accuracy: 0.4926
Epoch 9/100
45000/45000 [==============================] - 10s 212us/sample - loss: 1.2800 - accuracy: 0.5570 - val_loss: 1.5722 - val_accuracy: 0.4998
Epoch 10/100
45000/45000 [==============================] - 10s 214us/sample - loss: 1.2512 - accuracy: 0.5656 - val_loss: 1.4974 - val_accuracy: 0.5082
Epoch 11/100
45000/45000 [==============================] - 9s 203us/sample - loss: 1.2141 - accuracy: 0.5802 - val_loss: 1.6123 - val_accuracy: 0.4916
Epoch 12/100
45000/45000 [==============================] - 9s 201us/sample - loss: 1.1856 - accuracy: 0.5893 - val_loss: 1.5449 - val_accuracy: 0.5016
Epoch 13/100
45000/45000 [==============================] - 9s 204us/sample - loss: 1.1602 - accuracy: 0.5978 - val_loss: 1.6241 - val_accuracy: 0.5056
Epoch 14/100
45000/45000 [==============================] - 9s 199us/sample - loss: 1.1290 - accuracy: 0.6118 - val_loss: 1.6085 - val_accuracy: 0.4936
Epoch 15/100
45000/45000 [==============================] - 9s 198us/sample - loss: 1.1050 - accuracy: 0.6176 - val_loss: 1.6951 - val_accuracy: 0.4860
Epoch 16/100
45000/45000 [==============================] - 9s 201us/sample - loss: 1.0786 - accuracy: 0.6293 - val_loss: 1.5806 - val_accuracy: 0.5044
Epoch 17/100
45000/45000 [==============================] - 10s 212us/sample - loss: 1.0629 - accuracy: 0.6362 - val_loss: 1.5932 - val_accuracy: 0.4970
Epoch 18/100
45000/45000 [==============================] - 10s 215us/sample - loss: 1.0330 - accuracy: 0.6458 - val_loss: 1.5968 - val_accuracy: 0.5080
Epoch 19/100
45000/45000 [==============================] - 9s 195us/sample - loss: 1.0104 - accuracy: 0.6488 - val_loss: 1.6166 - val_accuracy: 0.5152
Epoch 20/100
45000/45000 [==============================] - 9s 206us/sample - loss: 0.9896 - accuracy: 0.6629 - val_loss: 1.6174 - val_accuracy: 0.5154
Epoch 21/100
45000/45000 [==============================] - 9s 211us/sample - loss: 0.9741 - accuracy: 0.6650 - val_loss: 1.7201 - val_accuracy: 0.5040
Epoch 22/100
45000/45000 [==============================] - 10s 220us/sample - loss: 0.9475 - accuracy: 0.6769 - val_loss: 1.7498 - val_accuracy: 0.5176
Epoch 23/100
45000/45000 [==============================] - 10s 216us/sample - loss: 0.9346 - accuracy: 0.6780 - val_loss: 1.7491 - val_accuracy: 0.5020
Epoch 24/100
45000/45000 [==============================] - 10s 223us/sample - loss: 1.1878 - accuracy: 0.6792 - val_loss: 1.6664 - val_accuracy: 0.4906
Epoch 25/100
45000/45000 [==============================] - 10s 219us/sample - loss: 0.9851 - accuracy: 0.6646 - val_loss: 1.7358 - val_accuracy: 0.5086
Epoch 26/100
45000/45000 [==============================] - 10s 220us/sample - loss: 0.9053 - accuracy: 0.6911 - val_loss: 1.8361 - val_accuracy: 0.5094
Epoch 27/100
45000/45000 [==============================] - 10s 215us/sample - loss: 0.8681 - accuracy: 0.7048 - val_loss: 1.8487 - val_accuracy: 0.5036
Epoch 28/100
45000/45000 [==============================] - 10s 220us/sample - loss: 0.8460 - accuracy: 0.7132 - val_loss: 1.8516 - val_accuracy: 0.5068
Epoch 29/100
45000/45000 [==============================] - 10s 223us/sample - loss: 0.8258 - accuracy: 0.7208 - val_loss: 1.9383 - val_accuracy: 0.5094
Epoch 30/100
45000/45000 [==============================] - 10s 216us/sample - loss: 0.8106 - accuracy: 0.7248 - val_loss: 2.0527 - val_accuracy: 0.4974
5000/5000 [==============================] - 0s 71us/sample - loss: 1.4974 - accuracy: 0.5082
</pre></div>
</div>
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>[1.4974345008850098, 0.5082]
</pre></div>
</div>
</div>
</div>
<p>The model reaches 50.8% accuracy on the validation set. That’s very slightly worse than without dropout (51.4%). With an extensive hyperparameter search, it might be possible to do better (I tried dropout rates of 5%, 10%, 20% and 40%, and learning rates 1e-4, 3e-4, 5e-4, and 1e-3), but probably not much better in this case.</p>
<p>Let’s use MC Dropout now. We will need the <code class="docutils literal notranslate"><span class="pre">MCAlphaDropout</span></code> class we used earlier, so let’s just copy it here for convenience:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MCAlphaDropout</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">AlphaDropout</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s create a new model, identical to the one we just trained (with the same weights), but with <code class="docutils literal notranslate"><span class="pre">MCAlphaDropout</span></code> dropout layers instead of <code class="docutils literal notranslate"><span class="pre">AlphaDropout</span></code> layers:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mc_model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">MCAlphaDropout</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">rate</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">AlphaDropout</span><span class="p">)</span> <span class="k">else</span> <span class="n">layer</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span>
<span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Then let’s add a couple utility functions. The first will run the model many times (10 by default) and it will return the mean predicted class probabilities. The second will use these mean probabilities to predict the most likely class for each instance:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mc_dropout_predict_probas</span><span class="p">(</span><span class="n">mc_model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">Y_probas</span> <span class="o">=</span> <span class="p">[</span><span class="n">mc_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Y_probas</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">mc_dropout_predict_classes</span><span class="p">(</span><span class="n">mc_model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">Y_probas</span> <span class="o">=</span> <span class="n">mc_dropout_predict_probas</span><span class="p">(</span><span class="n">mc_model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Y_probas</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s make predictions for all the instances in the validation set, and compute the accuracy:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">mc_dropout_predict_classes</span><span class="p">(</span><span class="n">mc_model</span><span class="p">,</span> <span class="n">X_valid_scaled</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">y_valid</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">accuracy</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>0.5094
</pre></div>
</div>
</div>
</div>
<p>We only get virtually no accuracy improvement in this case (from 50.8% to 50.9%).</p>
<p>So the best model we got in this exercise is the Batch Normalization model.</p>
</div>
<div class="section" id="f">
<h3>f.<a class="headerlink" href="#f" title="Permalink to this headline">¶</a></h3>
<p><em>Exercise: Retrain your model using 1cycle scheduling and see if it improves training speed and model accuracy.</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span>
                                 <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">,</span>
                                 <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">AlphaDropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">rates</span><span class="p">,</span> <span class="n">losses</span> <span class="o">=</span> <span class="n">find_learning_rate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">plot_lr_vs_loss</span><span class="p">(</span><span class="n">rates</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">([</span><span class="nb">min</span><span class="p">(</span><span class="n">rates</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">rates</span><span class="p">),</span> <span class="nb">min</span><span class="p">(</span><span class="n">losses</span><span class="p">),</span> <span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="nb">min</span><span class="p">(</span><span class="n">losses</span><span class="p">))</span> <span class="o">/</span> <span class="mf">1.4</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 45000 samples
45000/45000 [==============================] - 3s 60us/sample - loss: nan - accuracy: 0.1403
</pre></div>
</div>
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>[1e-05, 9.999868, 2.0895472, 3.482099260602679]
</pre></div>
</div>
<img alt="../../_images/11_training_deep_neural_networks_224_2.png" src="../../_images/11_training_deep_neural_networks_224_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span>
                                 <span class="n">kernel_initializer</span><span class="o">=</span><span class="s2">&quot;lecun_normal&quot;</span><span class="p">,</span>
                                 <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;selu&quot;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">AlphaDropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">onecycle</span> <span class="o">=</span> <span class="n">OneCycleScheduler</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">n_epochs</span><span class="p">,</span> <span class="n">max_rate</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid_scaled</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">),</span>
                    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">onecycle</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Train on 45000 samples, validate on 5000 samples
Epoch 1/15
45000/45000 [==============================] - 3s 69us/sample - loss: 2.0504 - accuracy: 0.2823 - val_loss: 1.7711 - val_accuracy: 0.3706
Epoch 2/15
45000/45000 [==============================] - 3s 57us/sample - loss: 1.7626 - accuracy: 0.3766 - val_loss: 1.7751 - val_accuracy: 0.3844
Epoch 3/15
45000/45000 [==============================] - 3s 59us/sample - loss: 1.6264 - accuracy: 0.4272 - val_loss: 1.6774 - val_accuracy: 0.4216
Epoch 4/15
45000/45000 [==============================] - 3s 57us/sample - loss: 1.5527 - accuracy: 0.4474 - val_loss: 1.6633 - val_accuracy: 0.4316
Epoch 5/15
45000/45000 [==============================] - 3s 59us/sample - loss: 1.4997 - accuracy: 0.4701 - val_loss: 1.5909 - val_accuracy: 0.4540
Epoch 6/15
45000/45000 [==============================] - 3s 60us/sample - loss: 1.4564 - accuracy: 0.4841 - val_loss: 1.5982 - val_accuracy: 0.4624
Epoch 7/15
45000/45000 [==============================] - 3s 56us/sample - loss: 1.4232 - accuracy: 0.4958 - val_loss: 1.6417 - val_accuracy: 0.4382
Epoch 8/15
45000/45000 [==============================] - 3s 58us/sample - loss: 1.3530 - accuracy: 0.5199 - val_loss: 1.5050 - val_accuracy: 0.4778
Epoch 9/15
45000/45000 [==============================] - 3s 57us/sample - loss: 1.2771 - accuracy: 0.5480 - val_loss: 1.5254 - val_accuracy: 0.4928
Epoch 10/15
45000/45000 [==============================] - 3s 56us/sample - loss: 1.2073 - accuracy: 0.5726 - val_loss: 1.5013 - val_accuracy: 0.5052
Epoch 11/15
45000/45000 [==============================] - 3s 57us/sample - loss: 1.1380 - accuracy: 0.5948 - val_loss: 1.4941 - val_accuracy: 0.5170
Epoch 12/15
45000/45000 [==============================] - 3s 56us/sample - loss: 1.0672 - accuracy: 0.6204 - val_loss: 1.5091 - val_accuracy: 0.5106
Epoch 13/15
45000/45000 [==============================] - 3s 56us/sample - loss: 0.9967 - accuracy: 0.6466 - val_loss: 1.5261 - val_accuracy: 0.5212
Epoch 14/15
45000/45000 [==============================] - 3s 58us/sample - loss: 0.9301 - accuracy: 0.6712 - val_loss: 1.5437 - val_accuracy: 0.5264
Epoch 15/15
45000/45000 [==============================] - 3s 59us/sample - loss: 0.8893 - accuracy: 0.6866 - val_loss: 1.5650 - val_accuracy: 0.5276
</pre></div>
</div>
</div>
</div>
<p>One cycle allowed us to train the model in just 15 epochs, each taking only 3 seconds (thanks to the larger batch size). This is over 3 times faster than the fastest model we trained so far. Moreover, we improved the model’s performance (from 50.8% to 52.8%). The batch normalized model reaches a slightly better performance, but it’s much slower to train.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks/book"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Jason Kuruzovich<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../../_static/js/index.js"></script>
    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-32817743-6', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>